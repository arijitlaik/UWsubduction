{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2D subduction\n",
    "\n",
    "\n",
    "This code was written by Dan Sandiford, Louis Moresi and the Underworld Team. It is licensed under the Creative Commons Attribution 4.0 International License . We offer this licence to encourage you to modify and share the examples and use them to help you in your research.\n",
    "\n",
    "<hr>\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by/4.0/88x31.png\" /></a><br />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#If run through Docker we'll point at the local 'unsupported dir.'\n",
    "#On hpc, the path should also include a directory holding the unsupported_dan.\n",
    "import os\n",
    "import sys\n",
    "\n",
    "if os.getcwd() == '/workspace/newSlab':\n",
    "    sys.path.append('../unsupported')\n",
    "\n",
    "#this does't actually need to be protected. More a reminder it's an interim measure\n",
    "try:\n",
    "    sys.path.append('../unsupported')\n",
    "except:\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../unsupported/unsupported_dan/utilities/__init__.py:9: UserWarning: \n",
      "\n",
      "The utilities module is not supported.\n",
      "Questions should be addressed to sandd@student.unimelb.edu.au \n",
      " \n",
      "  Questions should be addressed to sandd@student.unimelb.edu.au \\n \"\"\"\n",
      "../unsupported/unsupported_dan/interfaces/__init__.py:9: UserWarning: \n",
      "\n",
      "The interface module is not supported.\n",
      "Questions should be addressed to louis.moresi@unimelb.edu.au \n",
      " \n",
      "  Questions should be addressed to louis.moresi@unimelb.edu.au \\n \"\"\"\n",
      "../unsupported/unsupported_dan/faults/__init__.py:9: UserWarning: \n",
      "\n",
      "The fault module is not supported.\n",
      "Questions should be addressed to louis.moresi@unimelb.edu.au \n",
      " \n",
      "  Questions should be addressed to louis.moresi@unimelb.edu.au \\n \"\"\"\n",
      "../unsupported/unsupported_dan/alchemy/__init__.py:9: UserWarning: \n",
      "\n",
      "The alchemy module is not supported.\n",
      "Questions should be addressed to sandd@student.unimelb.edu.au \n",
      " \n",
      "  Questions should be addressed to sandd@student.unimelb.edu.au \\n \"\"\"\n",
      "../unsupported/unsupported_dan/easymodels/__init__.py:9: UserWarning: \n",
      "\n",
      "The easymodels module is not supported.\n",
      "Questions should be addressed to sandd@student.unimelb.edu.au \n",
      " \n",
      "  Questions should be addressed to sandd@student.unimelb.edu.au \\n \"\"\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import underworld as uw\n",
    "import math\n",
    "from underworld import function as fn\n",
    "import glucifer\n",
    "import os\n",
    "import sys\n",
    "from easydict import EasyDict as edict\n",
    "import operator\n",
    "import pickle\n",
    "\n",
    "\n",
    "#\n",
    "from unsupported_dan.utilities.interpolation import nn_evaluation\n",
    "from unsupported_dan.interfaces.marker2D import markerLine2D\n",
    "from unsupported_dan.faults.faults2D import fault2D, fault_collection\n",
    "from unsupported_dan.alchemy.materialGraph import MatGraph\n",
    "from unsupported_dan.easymodels.checkpoint import checkpoint\n",
    "from unsupported_dan.utilities.misc import cosine_taper\n",
    "from unsupported_dan.utilities.subduction import slab_top\n",
    "from unsupported_dan.utilities.mechanics import eig2d\n",
    "from unsupported_dan.utilities.phase_utils import phases\n",
    "from unsupported_dan.interfaces.smoothing2D import *\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#import ipython\n",
    "#IPython.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Setup output directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "############\n",
    "#Model letter and number\n",
    "############\n",
    "\n",
    "\n",
    "#Model letter identifier demarker\n",
    "Model = \"T\"\n",
    "\n",
    "#Model number identifier demarker:\n",
    "ModNum = 2\n",
    "\n",
    "#Any isolated letter / integer command line args are interpreted as Model/ModelNum\n",
    "\n",
    "if len(sys.argv) == 1:\n",
    "    ModNum = ModNum \n",
    "elif sys.argv[1] == '-f': #\n",
    "    ModNum = ModNum \n",
    "else:\n",
    "    for farg in sys.argv[1:]:\n",
    "        if not '=' in farg: #then Assume it's a not a paramter argument\n",
    "            try:\n",
    "                ModNum = int(farg) #try to convert everingthing to a float, else remains string\n",
    "            except ValueError:\n",
    "                Model  = farg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#Standard output directory setup\n",
    "###########\n",
    "\n",
    "outputPath = \"results\" + \"/\" +  str(Model) + \"/\" + str(ModNum) + \"/\" \n",
    "imagePath = outputPath + 'images/'\n",
    "filePath = outputPath + 'files/'\n",
    "#checkpointPath = outputPath + 'checkpoint/'\n",
    "dbPath = outputPath + 'gldbs/'\n",
    "xdmfPath = outputPath + 'xdmf/'\n",
    "outputFile = 'results_model' + Model + '_' + str(ModNum) + '.dat'\n",
    "\n",
    "if uw.rank()==0:\n",
    "    # make directories if they don't exist\n",
    "    if not os.path.isdir(outputPath):\n",
    "        os.makedirs(outputPath)\n",
    "    if not os.path.isdir(imagePath):\n",
    "        os.makedirs(imagePath)\n",
    "    if not os.path.isdir(dbPath):\n",
    "        os.makedirs(dbPath)\n",
    "    if not os.path.isdir(filePath):\n",
    "        os.makedirs(filePath)\n",
    "    if not os.path.isdir(xdmfPath):\n",
    "        os.makedirs(xdmfPath)\n",
    "        \n",
    "uw.barrier() #Barrier here so no procs run the check in the next cell too early"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#*************CHECKPOINT-BLOCK**************#\n",
    "\n",
    "#cp = checkpoint(outputPath + 'checkpoint/', loadpath='./results/A/1/checkpoint/10')\n",
    "cp = checkpoint(outputPath + 'checkpoint/')\n",
    "\n",
    "\n",
    "#*************CHECKPOINT-BLOCK**************#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#cp.dictDict, cp.objDict\n",
    "#cp.dictDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Model parameters and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#dp.potentialTemp - 273"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dp = edict({})\n",
    "#Main physical paramters\n",
    "dp.depth=1000e3                         #Depth\n",
    "dp.refDensity=3300.                        #reference density\n",
    "dp.refGravity=9.8                          #surface gravity\n",
    "dp.viscosityScale=1e20                       #reference upper mantle visc., \n",
    "dp.refDiffusivity=1e-6                     #thermal diffusivity\n",
    "dp.refExpansivity=3e-5                     #surface thermal expansivity\n",
    "dp.gasConstant=8.314                    #gas constant\n",
    "dp.specificHeat=1250.                   #Specific heat (Jkg-1K-1)\n",
    "dp.potentialTemp=1573.                  #mantle potential temp (K)\n",
    "dp.surfaceTemp=273.                     #surface temp (K)\n",
    "#Rheology - flow law paramters\n",
    "dp.cohesionMantle=20e6                   #mantle cohesion in Byerlee law\n",
    "dp.cohesionInterface=1e6                    #crust cohesion in Byerlee law\n",
    "dp.frictionMantle=0.2                   #mantle friction coefficient in Byerlee law (tan(phi))\n",
    "dp.frictionInterface=0.02                   #crust friction coefficient \n",
    "dp.diffusionPreExp=5.34e-10             #1./1.87e9, pre-exp factor for diffusion creep\n",
    "dp.diffusionEnergy=3e5 \n",
    "dp.diffusionVolume=5e-6\n",
    "dp.lowerMantlePreExp=4.23e-15           #1./2.36e14\n",
    "dp.lowerMantleEnergy=2.0e5\n",
    "dp.lowerMantleVolume=1.5e-6\n",
    "dp.lowerMantleViscFac = 30.\n",
    "#Fk approach to interface viscosity\n",
    "dp.delViscInterface = 1e4\n",
    "dp.refViscInterface = 1e20\n",
    "dp.refDepthInterface = 80e3\n",
    "#power law creep params\n",
    "dp.powerLawStrain = 1e-15\n",
    "dp.powerLawExp = 3.5\n",
    "\n",
    "#Rheology - cutoff values\n",
    "dp.viscosityMin=1e18\n",
    "dp.viscosityMax=1e25                #viscosity max in the mantle material\n",
    "dp.viscosityMinInterface=1e18               #viscosity min in the weak-crust / interface material\n",
    "dp.viscosityMaxInterface=1e25               #viscosity min in the weak-crust / interface material\n",
    "dp.ysMaxInterface = 50e6\n",
    "dp.yieldStressMax=300*1e6              #\n",
    "dp.interfaceViscCutoffDepth = 100e3\n",
    "dp.interfaceViscEndWidth = 20e3     \n",
    "\n",
    "#Intrinsic Lengths\n",
    "dp.mantleCrustDepth=10.*1e3              #Crust depth\n",
    "dp.faultThickness = 10.*1e3              #interface material (crust) an top of slabs\n",
    "dp.lowerMantleDepth=660.*1e3  \n",
    "dp.interfaceDestroyDepth=400.*1e3             #Beyond this depth, crust, interface, etc get destroyed\n",
    "dp.interfaceResetDepth=400.*1e3               #Beyond this depth there is no proximity accumulation()\n",
    "\n",
    "#Slab and plate init. parameters\n",
    "dp.subZoneLoc=-100e3                    #X position of subduction zone...km\n",
    "dp.maxDepth=150e3\n",
    "dp.radiusOfCurv = 350e3                          #radius of curvature\n",
    "dp.slabMaxAge=70e6                     #age of subduction plate at trench\n",
    "dp.opMaxAge=35e6                       #age of op\n",
    "dp.spAgeGrad = (-1./4)  # (y / cm.) The gradient direction is taken as away from the sz\n",
    "dp.opAgeGrad = (-1./8)  # (y / cm.) The gradient direction is taken as away from the sz\n",
    "#Misc\n",
    "dp.stickyAirDepth=100e3                 #depth of sticky air layer\n",
    "dp.viscosityStickyAir=1e19              #stick air viscosity, normal\n",
    "#derived params\n",
    "dp.deltaTemp = dp.potentialTemp-dp.surfaceTemp\n",
    "dp.tempGradMantle = (dp.refExpansivity*dp.refGravity*(dp.potentialTemp))/dp.specificHeat\n",
    "dp.tempGradSlab = (dp.refExpansivity*dp.refGravity*(dp.surfaceTemp + 400.))/dp.specificHeat\n",
    "\n",
    "#a velocity scale, used in some caes to set an approx viscosity in the interface\n",
    "dp.subVelocity = 4*(1/100.)*(1./(3600*24*365)) #m/s\n",
    "\n",
    "#op velocity will be set as a BC, or False\n",
    "dp.opVelocity = -1.*(1/100.)*(1./(3600*24*365)) \n",
    "\n",
    "\n",
    "#Modelling and Physics switches\n",
    "\n",
    "md = edict({})\n",
    "md.refineMeshStatic=True\n",
    "md.stickyAir=False\n",
    "md.aspectRatio=5.\n",
    "md.res=48\n",
    "md.ppc=35                                 #particles per cell\n",
    "md.elementType=\"Q1/dQ0\"\n",
    "#md.elementType=\"Q2/DPC1\"\n",
    "md.secInvFac=math.sqrt(1.)\n",
    "md.courantFac=0.5                         #extra limitation on timestepping\n",
    "md.thermal = True                        #thermal system or compositional\n",
    "md.swarmInitialFac = 0.6                 #initial swarm layout will be int(md.ppc*md.swarmInitialFac), popControl will densify later\n",
    "md.compBuoyancy = False\n",
    "md.nltol = 0.01\n",
    "md.maxSteps = 20000\n",
    "md.checkpointEvery = 200\n",
    "md.swarmUpdate = 10\n",
    "md.druckerAlpha = 0.\n",
    "md.druckerAlphaFault = 0.\n",
    "md.penaltyMethod = True\n",
    "md.opuniform = False\n",
    "md.spuniform = False\n",
    "md.opfixed = False\n",
    "md.spfixed = False\n",
    "md.buoyancyFac = 1.0\n",
    "md.restartParams = True #whether we load params on checkpoint restart. md.restartParams = True #whether we load params on checkpoint restart. \n",
    "#The following are time-based actions\n",
    "md.filesMy = 1.0e6 #dimensional time interval to write files\n",
    "md.diffuseInitial =  0. #5e6 # years to run initial diffusion for. Or set to zero.\n",
    "\n",
    "#some flags mostlt controlling the interface viscosity. \n",
    "md.interfaceType = 2 #1 for 'weak' crust, 2 for 'fault ' (isotropic)\n",
    "md.plasticInterface = 1 #non linear (plastic) of linear (effective viscosity)\n",
    "md.faultHeal=1\n",
    "md.faultLocFac = 1. #this is the relative location of the fault in terms of the fault thickess from the top of slab\n",
    "md.powerLaw = False\n",
    "md.viscCombine = 1 #zero here will use min(), anythin else toggles harmonic\n",
    "md.fixedRidges = False\n",
    "md.phaseBuoyancy = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#1/40."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0003699696000000001"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dp.maxDepth=110e3\n",
    "#dp.radiusOfCurv = 35e3\n",
    "dp.tempGradMantle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "####TEST BLOCK, smaller activation energy\n",
    "\n",
    "fracE = 0.6 #We want to multiply the activation Energy by this value\n",
    "delE= dp.diffusionEnergy - dp.diffusionEnergy*fracE\n",
    "dp.diffusionEnergy *= fracE\n",
    "dp.diffusionVolume *=0.8\n",
    "dp.diffusionPreExp /= np.exp(delE /(dp.gasConstant*dp.potentialTemp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "uw.barrier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "##Parse any command-line args\n",
    "\n",
    "from unsupported_dan.easymodels import easy_args\n",
    "sysArgs = sys.argv\n",
    "\n",
    "#We want to run this on both the paramter dict, and the model dict\n",
    "easy_args(sysArgs, dp)\n",
    "easy_args(sysArgs, md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "uw.barrier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sf = edict({})\n",
    "\n",
    "sf.lengthScale=2900e3\n",
    "sf.viscosityScale = dp.viscosityScale\n",
    "sf.stress = (dp.refDiffusivity*sf.viscosityScale)/sf.lengthScale**2\n",
    "#sf.lithGrad = dp.refDensity*dp.refGravity*(sf.lengthScale)**3/(sf.viscosityScale*dp.refDiffusivity) \n",
    "sf.lithGrad = (sf.viscosityScale*dp.refDiffusivity) /(dp.refDensity*dp.refGravity*(sf.lengthScale)**3)\n",
    "sf.velocity = dp.refDiffusivity/sf.lengthScale\n",
    "sf.strainRate = dp.refDiffusivity/(sf.lengthScale**2)\n",
    "sf.time = 1./sf.strainRate\n",
    "sf.actVolume = (dp.gasConstant*dp.deltaTemp)/(dp.refDensity*dp.refGravity*sf.lengthScale)\n",
    "sf.actEnergy = (dp.gasConstant*dp.deltaTemp)\n",
    "sf.diffusionPreExp = 1./sf.viscosityScale\n",
    "sf.deltaTemp  = dp.deltaTemp\n",
    "sf.pressureDepthGrad = (dp.refDensity*dp.refGravity*sf.lengthScale**3)/(dp.viscosityScale*dp.refDiffusivity)\n",
    "\n",
    "\n",
    "#dimesionless params\n",
    "ndp  = edict({})\n",
    "\n",
    "ndp.rayleigh = md.buoyancyFac*(dp.refExpansivity*dp.refDensity*dp.refGravity*dp.deltaTemp*sf.lengthScale**3)/(dp.viscosityScale*dp.refDiffusivity)\n",
    "\n",
    "#Take care with these definitions, \n",
    "ndp.surfaceTemp = dp.surfaceTemp/sf.deltaTemp  #Ts\n",
    "ndp.potentialTemp = dp.potentialTemp/sf.deltaTemp - ndp.surfaceTemp #Tp' = Tp - TS\n",
    "ndp.tempGradMantle = dp.tempGradMantle/(sf.deltaTemp/sf.lengthScale)\n",
    "ndp.tempGradSlab = dp.tempGradSlab/(sf.deltaTemp/sf.lengthScale)\n",
    "\n",
    "#lengths / distances\n",
    "ndp.depth = dp.depth/sf.lengthScale\n",
    "ndp.leftLim = -0.5*ndp.depth*md.aspectRatio\n",
    "ndp.rightLim = 0.5*ndp.depth*md.aspectRatio\n",
    "ndp.faultThickness = dp.faultThickness/sf.lengthScale\n",
    "ndp.mantleCrustDepth =  dp.mantleCrustDepth/sf.lengthScale\n",
    "ndp.interfaceDestroyDepth = dp.interfaceDestroyDepth/sf.lengthScale\n",
    "ndp.interfaceResetDepth = dp.interfaceResetDepth/sf.lengthScale\n",
    "ndp.lowerMantleDepth = dp.lowerMantleDepth/sf.lengthScale\n",
    "\n",
    "\n",
    "#times - for convenience and sanity the dimensional values are in years, conversion to seconds happens here\n",
    "ndp.slabMaxAge =  dp.slabMaxAge*(3600*24*365)/sf.time\n",
    "ndp.opMaxAge = dp.opMaxAge*(3600*24*365)/sf.time\n",
    "\n",
    "#Rheology - flow law paramters\n",
    "ndp.cohesionMantle=dp.cohesionMantle/sf.stress                  #mantle cohesion in Byerlee law\n",
    "ndp.cohesionInterface=dp.cohesionInterface/sf.stress                  #crust cohesion in Byerlee law\n",
    "ndp.frictionMantle=dp.frictionMantle/sf.lithGrad                  #mantle friction coefficient in Byerlee law (tan(phi))\n",
    "ndp.frictionInterface=dp.frictionInterface/sf.lithGrad                  #crust friction coefficient \n",
    "ndp.diffusionPreExp=dp.diffusionPreExp/sf.diffusionPreExp                #pre-exp factor for diffusion creep\n",
    "ndp.diffusionEnergy=dp.diffusionEnergy/sf.actEnergy\n",
    "ndp.diffusionVolume=dp.diffusionVolume/sf.actVolume\n",
    "ndp.lowerMantlePreExp=dp.lowerMantlePreExp/sf.diffusionPreExp \n",
    "ndp.lowerMantleEnergy=dp.lowerMantleEnergy/sf.actEnergy\n",
    "ndp.lowerMantleVolume=dp.lowerMantleVolume/sf.actVolume\n",
    "ndp.yieldStressMax=dp.yieldStressMax/sf.stress \n",
    "#Fk approach to interface viscosity\n",
    "ndp.logDelVisc = np.log(dp.delViscInterface)\n",
    "ndp.refViscInterface = dp.refViscInterface/sf.viscosityScale\n",
    "ndp.refDepthInterface = dp.refDepthInterface/sf.lengthScale\n",
    "#\n",
    "ndp.powerLawStrain = dp.powerLawStrain/sf.strainRate\n",
    "ndp.powerLawExp = dp.powerLawExp\n",
    "\n",
    "#Rheology - cutoff values\n",
    "ndp.viscosityMin= dp.viscosityMin /sf.viscosityScale\n",
    "ndp.viscosityMax=dp.viscosityMax/sf.viscosityScale\n",
    "ndp.viscosityMinInterface= dp.viscosityMinInterface /sf.viscosityScale\n",
    "ndp.viscosityMaxInterface= dp.viscosityMaxInterface /sf.viscosityScale\n",
    "ndp.lowerMantleViscFac = dp.lowerMantleViscFac\n",
    "ndp.interfaceViscCutoffDepth = dp.interfaceViscCutoffDepth/sf.lengthScale\n",
    "ndp.interfaceViscEndWidth = dp.interfaceViscEndWidth/sf.lengthScale\n",
    "ndp.ysMaxInterface  = dp.ysMaxInterface/sf.stress\n",
    "\n",
    "\n",
    "#Slab and plate init. parameters\n",
    "ndp.subZoneLoc = dp.subZoneLoc/sf.lengthScale\n",
    "ndp.maxDepth = dp.maxDepth/sf.lengthScale\n",
    "ndp.radiusOfCurv = dp.radiusOfCurv/sf.lengthScale\n",
    "ndp.subVelocity = dp.subVelocity/sf.velocity\n",
    "ndp.opVelocity = dp.opVelocity/sf.velocity\n",
    "ndp.spAgeGrad = dp.spAgeGrad* (3600*24*365)*(100.)*(sf.lengthScale/sf.time)\n",
    "ndp.opAgeGrad = dp.opAgeGrad* (3600*24*365)*(100.)*(sf.lengthScale/sf.time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#1. - (70/2900.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#dp.subVelocity\n",
    "\n",
    "#ndp.tempGradMantle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9655172413793104"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sf.time\n",
    "#ndp.opAgeGrad\n",
    "#sf.time/(3600*24*365*1e6)\n",
    "#15.9/(ndp.diffusionEnergy)\n",
    "#ndp.tempGradMantle\n",
    "\n",
    "1. - (100./2900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#*************CHECKPOINT-BLOCK**************#\n",
    "\n",
    "\n",
    "#if restart, attempt to read in saved dicts. \n",
    "if cp.restart and md.restartParams:\n",
    "    try:\n",
    "        with open(os.path.join(cp.loadpath, 'dp.pkl'), 'rb') as fp:\n",
    "                            dp = pickle.load(fp)\n",
    "        with open(os.path.join(cp.loadpath, 'sf.pkl'), 'rb') as fp:\n",
    "                            sf = pickle.load(fp)\n",
    "        with open(os.path.join(cp.loadpath, 'md.pkl'), 'rb') as fp:\n",
    "                            md = pickle.load(fp)\n",
    "\n",
    "    except:\n",
    "        print(\"couldn't load paramter dictionaries on restart\")\n",
    "\n",
    "\n",
    "    \n",
    "#add dicts to the checkpointinng object\n",
    "cp.addDict(dp, 'dp')\n",
    "cp.addDict(sf, 'sf')\n",
    "cp.addDict(md, 'md')\n",
    "#*************CHECKPOINT-BLOCK**************#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#1. - (100e3/sf.lengthScale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Inform checkpoint object of values we'll be tracking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Metrics / values we want to track and save get stored in a dictionary of lists.\n",
    "#By adding this dictionary to the checkpoint object, \n",
    "#it becomes part of regular checkpointing proceedure\n",
    "\n",
    "#It is likely we'll want to update and save the dictionary more often that checkpointing frequency\n",
    "#in this case, we could pickle the dictionary, or use np.savez(fname, **valuesDict)\n",
    "\n",
    "#to update a value-list in the dictionary, just use:\n",
    "#valuesDict.valueList2.append(newValue)\n",
    "\n",
    "#*************CHECKPOINT-BLOCK**************#\n",
    "\n",
    "if not cp.restart:\n",
    "    valuesDict = edict({})\n",
    "    valuesDict.timeAtSave = []\n",
    "    valuesDict.stepAtSave = []\n",
    "    valuesDict.maxVxSurf = []\n",
    "    valuesDict.minVxSurf = []\n",
    "    valuesDict.areaintLith = []\n",
    "    valuesDict.vdintLith = []\n",
    "    valuesDict.vdintUM = []\n",
    "    valuesDict.vdintLM = []\n",
    "    valuesDict.areaintSlabLM = []\n",
    "    valuesDict.vdintSlabLM = []\n",
    "    valuesDict.areaintInterface = []\n",
    "    valuesDict.vdintInterface= []\n",
    "    valuesDict.potentialWork= []\n",
    "    valuesDict.vdintLower= []\n",
    "    valuesDict.areaintLower= []\n",
    "    valuesDict.vdintLowerBending= []\n",
    "    valuesDict.areaintLowerBending= []\n",
    "    valuesDict.subZoneLoc = []\n",
    "    valuesDict.spRidgeLoc = []\n",
    "    valuesDict.opRidgeLoc = []\n",
    "    valuesDict.wedgeHotCornerX = []\n",
    "    valuesDict.wedgeHotCornerY = []\n",
    "    valuesDict.tempInt = []\n",
    "    valuesDict.nusseltTop = []\n",
    "    valuesDict.critWedgeTempArea = []\n",
    "\n",
    "\n",
    "if cp.restart:\n",
    "    try:\n",
    "        with open(os.path.join(cp.loadpath, 'vd.pkl'), 'rb') as fp:\n",
    "            valuesDict= pickle.load(fp)\n",
    "    except:\n",
    "        print(\"couldn't load paramter dictionaries on restart\")\n",
    "        \n",
    "\n",
    "cp.addDict(valuesDict, 'vd')\n",
    "#*************CHECKPOINT-BLOCK**************#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#define the location of plate boundaries\n",
    "\n",
    "\n",
    "#if not cp.restart:\n",
    "subZoneLoc = fn.misc.constant(ndp.subZoneLoc)\n",
    "spRidgeLoc = fn.misc.constant(ndp.leftLim)\n",
    "opRidgeLoc = fn.misc.constant(ndp.rightLim)\n",
    "\n",
    "if cp.restart:\n",
    "    try:\n",
    "        subZoneLoc = fn.misc.constant(valuesDict.subZoneLoc[-1]) #this one carries the upadatin' values\n",
    "        spRidgeLoc = fn.misc.constant(valuesDict.spRidgeLoc[-1])\n",
    "        opRidgeLoc = fn.misc.constant(valuesDict.opRidgeLoc[-1])\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Build Mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Domain and Mesh paramters\n",
    "yres = int(md.res)\n",
    "xres = int(md.res*12) \n",
    "\n",
    "\n",
    "\n",
    "mesh = uw.mesh.FeMesh_Cartesian( elementType = (md.elementType),\n",
    "                                 elementRes  = (xres, yres), \n",
    "                                 minCoord    = (ndp.leftLim, 1. - ndp.depth), \n",
    "                                 maxCoord    = (ndp.rightLim, 1.)) \n",
    "\n",
    "velocityField   = uw.mesh.MeshVariable( mesh=mesh,         nodeDofCount=2 )\n",
    "pressureField   = uw.mesh.MeshVariable( mesh=mesh.subMesh, nodeDofCount=1 )\n",
    "temperatureField    = uw.mesh.MeshVariable( mesh=mesh,         nodeDofCount=1 )\n",
    "\n",
    "if md.thermal:\n",
    "    temperatureDotField = uw.mesh.MeshVariable( mesh=mesh,         nodeDofCount=1 ) #create this only if Adv-diff\n",
    "    diffusivityFn = fn.misc.constant(1.)\n",
    "    \n",
    "    \n",
    "    \n",
    "# Any extra mesh vars. we want to define (mostly to facilite saving as xdmf)\n",
    "strainRateField    = uw.mesh.MeshVariable( mesh=mesh,         nodeDofCount=1 )\n",
    "viscosityField    = uw.mesh.MeshVariable( mesh=mesh,         nodeDofCount=1 )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#*************CHECKPOINT-BLOCK**************#\n",
    "cp.addObject(velocityField,'velocityField')\n",
    "cp.addObject(pressureField,'pressureField')\n",
    "if md.thermal:\n",
    "    cp.addObject(temperatureField,'temperatureField')\n",
    "    cp.addObject(temperatureDotField,'temperatureDotField')\n",
    "    \n",
    "\n",
    "#*************CHECKPOINT-BLOCK**************#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#print(cp.objDict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#*************CHECKPOINT-BLOCK**************#\n",
    "\n",
    "if cp.restart:\n",
    "    velocityField.load(cp.loadpath + '/velocityField.h5')\n",
    "    pressureField.load(cp.loadpath + '/pressureField.h5')\n",
    "    if md.thermal:\n",
    "        temperatureField.load(cp.loadpath + '/temperatureField.h5')\n",
    "        temperatureDotField.load(cp.loadpath + '/temperatureDotField.h5')\n",
    "#*************CHECKPOINT-BLOCK**************#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Misc. functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#miscellaneous Uw functions, geometry measurements\n",
    "\n",
    "coordinate = fn.input()\n",
    "depthFn = mesh.maxCoord[1] - coordinate[1] #a function providing the depth\n",
    "\n",
    "\n",
    "xFn = coordinate[0]  #a function providing the x-coordinate\n",
    "yFn = coordinate[1]\n",
    "\n",
    "#We'll use this for integrals\n",
    "\n",
    "surfaceIndexSet=mesh.specialSets[\"MaxJ_VertexSet\"]\n",
    "_surfLength  = uw.utils.Integral( 1., mesh=mesh, integrationType='Surface', surfaceIndexSet=surfaceIndexSet)\n",
    "surfLength = _surfLength.evaluate()[0]\n",
    "\n",
    "\n",
    "#Create a binary circle\n",
    "def inCircleFnGenerator(centre, radius):\n",
    "    coord = fn.input()\n",
    "    offsetFn = coord - centre\n",
    "    return fn.math.dot( offsetFn, offsetFn ) < radius**2\n",
    "\n",
    "\n",
    "###################\n",
    "#Create integral, max/min templates \n",
    "###################\n",
    "\n",
    "globRFn = fn.misc.constant(1.)\n",
    "\n",
    "def volumeint(Fn = 1., rFn=globRFn):\n",
    "    return uw.utils.Integral( Fn*rFn,  mesh )\n",
    "\n",
    "def surfint(Fn = 1., rFn=globRFn, surfaceIndexSet=mesh.specialSets[\"MaxJ_VertexSet\"]):\n",
    "    return uw.utils.Integral( Fn*rFn, mesh=mesh, integrationType='Surface', surfaceIndexSet=surfaceIndexSet)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Static Mesh refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if md.refineMeshStatic:\n",
    "    mesh.reset()\n",
    "\n",
    "    jWalls = mesh.specialSets[\"MinJ_VertexSet\"] + mesh.specialSets[\"MaxJ_VertexSet\"]\n",
    "    yFn = coordinate[1]\n",
    "    yField = uw.mesh.MeshVariable( mesh=mesh, nodeDofCount=1 )\n",
    "    yField.data[:] = 0.\n",
    "    yBC = uw.conditions.DirichletCondition( variable=yField, indexSetsPerDof=(jWalls,) )\n",
    "\n",
    "    # set bottom wall temperature bc\n",
    "    for index in mesh.specialSets[\"MinJ_VertexSet\"]:\n",
    "        yField.data[index] = mesh.minCoord[1]\n",
    "    # set top wall temperature bc\n",
    "    for index in mesh.specialSets[\"MaxJ_VertexSet\"]:\n",
    "        yField.data[index] = mesh.maxCoord[1]\n",
    "\n",
    "\n",
    "\n",
    "    s = 4\n",
    "    intensityFac = 6.\n",
    "    intensityFn = (((yFn - mesh.minCoord[1])/(mesh.maxCoord[1]-mesh.minCoord[1]))**s)\n",
    "    intensityFn *= intensityFac\n",
    "    intensityFn += 1.\n",
    "\n",
    "\n",
    "    yLaplaceEquation = uw.systems.SteadyStateHeat(temperatureField=yField, fn_diffusivity=intensityFn, conditions=[yBC,])\n",
    "\n",
    "    # get the demarker heat equation solver\n",
    "    yLaplaceSolver = uw.systems.Solver(yLaplaceEquation)\n",
    "    # solve\n",
    "    yLaplaceSolver.solve()\n",
    "\n",
    "\n",
    "    #Get the array of Y positions - copy may be necessary, not sure. \n",
    "    newYpos = yField.data.copy() \n",
    "\n",
    "    uw.barrier()\n",
    "    with mesh.deform_mesh():\n",
    "         mesh.data[:,1] = newYpos[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Boundary Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Stokes BCs\n",
    "\n",
    "iWalls = mesh.specialSets[\"MinI_VertexSet\"] + mesh.specialSets[\"MaxI_VertexSet\"]\n",
    "jWalls = mesh.specialSets[\"MinJ_VertexSet\"] + mesh.specialSets[\"MaxJ_VertexSet\"]\n",
    "tWalls = mesh.specialSets[\"MaxJ_VertexSet\"]\n",
    "bWalls =mesh.specialSets[\"MinJ_VertexSet\"]\n",
    "      \n",
    "        \n",
    "freeslipBC = uw.conditions.DirichletCondition( variable      = velocityField, \n",
    "                                               indexSetsPerDof = ( iWalls, jWalls) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Set a constat velocity BC on the upper plate\n",
    "#(having bcs extend right to the side wall was very unstable)\n",
    "\n",
    "limBCs = ndp.subZoneLoc + (200e3/sf.lengthScale)\n",
    "\n",
    "checkFn = fn.branching.conditional([(xFn < limBCs, False),\n",
    "                                       (xFn  > ndp.rightLim - (200e3/sf.lengthScale), False),\n",
    "                                  (True, True)])\n",
    "\n",
    "\n",
    "velnodesMask = np.where(checkFn.evaluate(tWalls) == True)[0] #gives the indeces of the tWalls array \n",
    "velnodes = tWalls.data[velnodesMask] #gets that actual node nos\n",
    "\n",
    "velnodeset = mesh.specialSets[\"Empty\"]\n",
    "velnodeset += velnodes\n",
    "\n",
    "if ndp.opVelocity:\n",
    "    freeslipBC = uw.conditions.DirichletCondition( variable      = velocityField, \n",
    "                                               indexSetsPerDof = ( iWalls + velnodeset, jWalls) )\n",
    "    \n",
    "    if velnodeset.data.shape[0]:\n",
    "        velocityField.data[velnodeset.data, 0] = ndp.opVelocity\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Energy BCs\n",
    "\n",
    "if md.thermal:\n",
    "    dirichTempBC = uw.conditions.DirichletCondition(     variable=temperatureField, \n",
    "                                              indexSetsPerDof=(tWalls,) )\n",
    "    \n",
    "    #in this case we imposed a fixed temp along the sidewalls\n",
    "    if md.fixedRidges:\n",
    "        dirichTempBC = uw.conditions.DirichletCondition(     variable=temperatureField, \n",
    "                                              indexSetsPerDof=(tWalls + iWalls,) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Swarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Materials\n",
    "mantleID = 0\n",
    "crustID = 1\n",
    "airID = 2      #in case we use sticky air\n",
    "\n",
    "#list of all material indexes\n",
    "material_list = [mantleID, crustID, airID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#*************CHECKPOINT-BLOCK**************#\n",
    "\n",
    "swarm = uw.swarm.Swarm(mesh=mesh, particleEscape=True)\n",
    "cp.addObject(swarm,'swarm')\n",
    "materialVariable      = swarm.add_variable( dataType=\"int\", count=1 )\n",
    "cp.addObject(materialVariable,'materialVariable')\n",
    "proxyTempVariable = swarm.add_variable( dataType=\"double\", count=1 )\n",
    "proximityVariable      = swarm.add_variable( dataType=\"int\", count=1 )\n",
    "cp.addObject(proximityVariable,'proximityVariable')\n",
    "ageVariable      = swarm.add_variable( dataType=\"double\", count=1 )\n",
    "cp.addObject(ageVariable,'ageVariable')\n",
    "\n",
    "if not md.thermal:\n",
    "    cp.addObject(proxyTempVariable,'proxyTempVariable')\n",
    "\n",
    "\n",
    "if cp.restart:\n",
    "    swarm.load(cp.loadpath + '/swarm.h5')\n",
    "    materialVariable.load(cp.loadpath + '/materialVariable.h5')\n",
    "    proximityVariable.load(cp.loadpath + '/proximityVariable.h5')\n",
    "    ageVariable.load(cp.loadpath + '/ageVariable.h5')\n",
    "    if not md.thermal:\n",
    "        proxyTempVariable.load(cp.loadpath + '/proxyTempVariable.h5')   \n",
    "\n",
    "\n",
    "else:\n",
    "    layout = uw.swarm.layouts.PerCellRandomLayout(swarm=swarm, particlesPerCell=int(md.ppc*md.swarmInitialFac))\n",
    "    swarm.populate_using_layout( layout=layout ) # Now use it to populate.\n",
    "    proxyTempVariable.data[:] = 0.0\n",
    "    materialVariable.data[:] = mantleID\n",
    "    proximityVariable.data[:] = 0.0\n",
    "\n",
    "#*************CHECKPOINT-BLOCK**************#\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#These variables don't need checkpointing. They can / should be rebuilt\n",
    "\n",
    "signedDistanceVariable = swarm.add_variable( dataType=\"double\", count=1 )\n",
    "#directorVector   = swarm.add_variable( dataType=\"double\", count=2)\n",
    "\n",
    "#directorVector.data[:,:] = 0.0\n",
    "signedDistanceVariable.data[:] = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Pass this to Figures to see full extent\n",
    "bBox=((mesh.minCoord[0], mesh.minCoord[1]),(mesh.maxCoord[0], mesh.maxCoord[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Initial Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#plate depth\n",
    "\n",
    "#Flags to control plate behaviour\n",
    "#md.opuniform\n",
    "#md.spuniform\n",
    "#md.opfixed\n",
    "#md.spfixed\n",
    "\n",
    "#T&S 4.126\n",
    "thicknessAtTrench = 2.32*math.sqrt(1.*ndp.slabMaxAge)\n",
    "\n",
    "#the basic plate age Fns, defined by age at temp and age gradient\n",
    "    \n",
    "if dp.spAgeGrad:\n",
    "    spAge = fn.math.abs(ndp.slabMaxAge + ndp.spAgeGrad*fn.math.abs(ndp.subZoneLoc - xFn))\n",
    "else:\n",
    "    spAge = ndp.slabMaxAge*fn.math.abs((mesh.minCoord[0] - xFn)/(ndp.subZoneLoc - mesh.minCoord[0]))\n",
    "\n",
    "if dp.opAgeGrad: #likewise\n",
    "    opAge = fn.math.abs(ndp.opMaxAge + ndp.opAgeGrad*fn.math.abs(ndp.subZoneLoc - xFn))\n",
    "else:\n",
    "    opAge = ndp.opMaxAge*fn.math.abs((mesh.maxCoord[0] - xFn)/(ndp.subZoneLoc - mesh.maxCoord[0]))\n",
    " \n",
    "#\n",
    "opAge = fn.misc.min(opAge, ndp.opMaxAge)\n",
    "spAge = fn.misc.min(spAge, ndp.slabMaxAge)\n",
    "\n",
    "\n",
    "\n",
    "#unless we specify fixing the plate to the sidwalls, we'll inforce a boundary\n",
    "\n",
    "sig = 150e3/sf.lengthScale\n",
    "ridgeFn = 1. -  \\\n",
    "                fn.math.exp(-1.*(xFn - mesh.minCoord[0])**2/(2 * sig**2))- \\\n",
    "                fn.math.exp(-1.*(xFn - mesh.maxCoord[0])**2/(2 * sig**2))\n",
    "if not md.spfixed:\n",
    "    spAge = ridgeFn*spAge\n",
    "else:\n",
    "    pass\n",
    "        \n",
    "if not md.opfixed:\n",
    "    opAge = ridgeFn*opAge\n",
    "else:\n",
    "    pass\n",
    "\n",
    "#we need to apply the sp age in the slab region as well\n",
    "#this is only needed for ageSp < ageOp. \n",
    "#however, this fix only works when circGradientFn is used to define the slab\n",
    "slabCirc = inCircleFnGenerator((ndp.subZoneLoc, 1.0 - ndp.radiusOfCurv), ndp.radiusOfCurv)\n",
    "\n",
    "proxyageFn = fn.branching.conditional([(xFn <= ndp.subZoneLoc, spAge), #idea is to make this arbitrarily complex\n",
    "                                       (slabCirc > 0.9, spAge),\n",
    "                                  (True, opAge)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#%pylab inline\n",
    "#fig, ax = plt.subplots()\n",
    "\n",
    "#ax.plot(opAge.evaluate(tWalls), c= 'r')\n",
    "#ax.plot(spAge.evaluate(tWalls), c= 'b')\n",
    "#ax.hlines(ndp.slabMaxAge, 0, 600 )\n",
    "#ax.hlines(ndp.opMaxAge, 0, 600 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Marker lines  for slab, fault, tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Create some slab gradient functions to use with slab_top()\n",
    "\n",
    "\n",
    "def linearGradientFn(S):\n",
    "    return np.tan(np.deg2rad(-45.))\n",
    "\n",
    "\n",
    "def circGradientFn(S):\n",
    "    if S == 0.:\n",
    "        return 0.\n",
    "    elif S < ndp.radiusOfCurv:\n",
    "        return max(-S/np.sqrt((ndp.radiusOfCurv**2 - S**2)), -1e3)\n",
    "    else:\n",
    "        return -1e5\n",
    "    \n",
    "    \n",
    "def polyGradientFn(S):\n",
    "    if S == 0.:\n",
    "        return 0.\n",
    "    else:\n",
    "        return -1*(S/ndp.radiusOfCurv)**2\n",
    "    \n",
    "    \n",
    "#def specialFn(S):\n",
    "#    if S == 0.:\n",
    "#        return 0.\n",
    "#    elif S < (20/2900.):\n",
    "#        return max(-S/np.sqrt((ndp.radiusOfCurv**2 - S**2)), -0.75)\n",
    "#    else:\n",
    "#        return -0.75\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### slab top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#ndp.ysMaxInterf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ds_fault = 2e3/sf.lengthScale\n",
    "normal = [1.,0.]\n",
    "\n",
    "#slabdata = slab_top([ndp.subZoneLoc, 1.0], normal, linearGradientFn, ds_fault, ndp.maxDepth, mesh)\n",
    "#slabdata= slab_top([ndp.subZoneLoc, 1.0], normal, polyGradientFn, ds_fault, ndp.maxDepth, mesh)\n",
    "slabdata = slab_top([ndp.subZoneLoc, 1.0], normal, circGradientFn, ds_fault, ndp.maxDepth, mesh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "slabxs = slabdata[:,0]\n",
    "slabys = slabdata[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#%pylab inline\n",
    "#fig, ax = plt.subplots()\n",
    "#ax.scatter(slabxs, slabys)\n",
    "#ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "slabLine = markerLine2D(mesh, velocityField, slabxs, slabys, thicknessAtTrench, 1., insidePt=(-0.5,0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#markerLine2D?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Assign the signed distance for the slab - in this case we only want the portion where the signed distance is positive\n",
    "\n",
    "#Note distance=2.*thicknessAtTrench: we actually want to allow distance greater than thicknessAtTrench in the kDTree query, \n",
    "#as some of these distances will not be orthogonal to the marker line, the dot product in the function will project these distances onto the normal vector\n",
    "#We'll cull distances greater than thicknessAtTrench with a numpy boolean slice - this is a big advantage in parallel\n",
    "\n",
    "sd, pts = slabLine.compute_signed_distance(swarm.particleCoordinates.data, distance=2.*thicknessAtTrench)\n",
    "signedDistanceVariable.data[np.logical_and(sd>0, sd<=slabLine.thickness)] = sd[np.logical_and(sd>0, sd<=slabLine.thickness)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "slabXConds = operator.and_(xFn > slabxs.min(), xFn < slabxs.max())\n",
    "slabYConds = depthFn < 1. - slabys.min()\n",
    "\n",
    "#Two functions we'll use to limit the region of the initial thermal stancil\n",
    "slabRegion =  fn.branching.conditional([(operator.and_(slabXConds,slabYConds), True),\n",
    "                          (True, False)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "bufferlength = 1e3/sf.lengthScale\n",
    "\n",
    "plateDepthFn = fn.branching.conditional([(depthFn < thicknessAtTrench, depthFn),\n",
    "                                        (True, 1.)])\n",
    "\n",
    "#plateTempProxFn = fn.math.erf((depthFn*sf.lengthScale)/(2.3*fn.math.sqrt(dp.refDiffusivity*proxyageFn)))\n",
    "plateTempProxFn = ndp.potentialTemp*fn.math.erf((plateDepthFn)/(2.*fn.math.sqrt(1.*proxyageFn)))\n",
    "\n",
    "#slabTempProx  = fn.math.erf((signedDistanceVariable*sf.lengthScale)/(2.*fn.math.sqrt(dp.refDiffusivity*proxyageFn)))\n",
    "slabTempProx  = ndp.potentialTemp*fn.math.erf((signedDistanceVariable)/(2.*np.sqrt(1.*ndp.slabMaxAge)))\n",
    "\n",
    "\n",
    "proxytempConds = fn.branching.conditional([(signedDistanceVariable < bufferlength, plateTempProxFn),\n",
    "                          (slabRegion,  fn.misc.min(slabTempProx , plateTempProxFn)),                 \n",
    "\n",
    "                          (True, plateTempProxFn)]) \n",
    "\n",
    "\n",
    "#*************CHECKPOINT-BLOCK**************#\n",
    "\n",
    "if not cp.restart:\n",
    "    proxyTempVariable.data[:] = proxytempConds.evaluate(swarm)\n",
    "    \n",
    "\n",
    "#*************CHECKPOINT-BLOCK**************#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#cp.restart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### marker\n",
    "\n",
    "In this notebook, the markerLine helps us set up the weak interface material, as well as tracking various flow metrics\n",
    "\n",
    "It could also be used it to define a proximity of Transversely Isotropic frictional behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "morexs = np.arange(mesh.minCoord[0] + 100e3/sf.lengthScale, ndp.subZoneLoc, ds_fault)[:-1]\n",
    "moreys = mesh.maxCoord[1]*np.ones(morexs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Build marker: copy the slab line, then move using the normal vector (director)\n",
    "#or, if checkpoint restart, load swarm\n",
    "\n",
    "markerxs = np.concatenate((morexs,slabxs[:-2]))\n",
    "markerys = np.concatenate((moreys,slabys[:-2]))\n",
    "\n",
    "\n",
    "marker = markerLine2D(mesh, velocityField,[], [], ndp.faultThickness,  1, insidePt=(-0.5,0.5))\n",
    "\n",
    "\n",
    "#*************CHECKPOINT-BLOCK**************#\n",
    "cp.addObject(marker.swarm,'marker')\n",
    "\n",
    "\n",
    "if not cp.restart:\n",
    "    marker.add_points(markerxs, markerys)\n",
    "    with marker.swarm.deform_swarm():\n",
    "        marker.swarm.particleCoordinates.data[:] += marker.director.data*ndp.faultThickness\n",
    "        \n",
    "else:\n",
    "    marker.swarm.load(cp.loadpath + '/marker.h5')\n",
    "#*************CHECKPOINT-BLOCK**************#\n",
    "    \n",
    "\n",
    "marker.rebuild()\n",
    "marker.swarm.update_particle_owners()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#marker.swarm.particleCoordinates.data.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#*************CHECKPOINT-BLOCK**************#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got to test point\n"
     ]
    }
   ],
   "source": [
    "print('got to test point')\n",
    "\n",
    "#uw.barrier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#set the material variable with the markerLine\n",
    "\n",
    "sd, pts0 = marker.compute_signed_distance(swarm.particleCoordinates.data, distance=ndp.mantleCrustDepth)\n",
    "\n",
    "#*************CHECKPOINT-BLOCK**************#\n",
    "if not cp.restart:\n",
    "    \n",
    "    materialVariable.data[np.logical_and(sd < 0, sd > -1*ndp.mantleCrustDepth)] = crustID\n",
    "    #materialVariable.data[np.logical_and(sd > 0,sd < ndp.mantleHarzDepth)] = harzID\n",
    "#*************CHECKPOINT-BLOCK**************#\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:1: DeprecationWarning: object of type <type 'float'> cannot be safely interpreted as an integer.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "surfacexs = np.linspace(mesh.minCoord[0], mesh.maxCoord[0], md.res*md.aspectRatio*2)\n",
    "surfaceys = np.ones(surfacexs.shape[0])\n",
    "surfaceLine = markerLine2D(mesh, velocityField,surfacexs, surfaceys , ndp.faultThickness,  2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#variables for surface\n",
    "\n",
    "surfVelx = uw.swarm.SwarmVariable(surfaceLine.swarm, 'double', 1)\n",
    "surfStrain = uw.swarm.SwarmVariable(surfaceLine.swarm, 'double', 1)\n",
    "surfVisc = uw.swarm.SwarmVariable(surfaceLine.swarm, 'double', 1)\n",
    "surfTgrad = uw.swarm.SwarmVariable(surfaceLine.swarm, 'double', 1)\n",
    "surfPres = uw.swarm.SwarmVariable(surfaceLine.swarm, 'double', 1)\n",
    "\n",
    "\n",
    "#variables for mid-lithsphere (saved on surface swarm)\n",
    "midlithEvalEvalPoints = uw.swarm.SwarmVariable(surfaceLine.swarm, 'double', 2)\n",
    "midlithVisc = uw.swarm.SwarmVariable(surfaceLine.swarm, 'double', 1)\n",
    "midlithSr2Inv = uw.swarm.SwarmVariable(surfaceLine.swarm, 'double', 1)\n",
    "midlithVelX = uw.swarm.SwarmVariable(surfaceLine.swarm, 'double', 1)\n",
    "midlithStrainTens = uw.swarm.SwarmVariable(surfaceLine.swarm, 'double', 3)\n",
    "\n",
    "#variables for upper-lithsphere (saved on surface swarm)\n",
    "uplithEvalEvalPoints = uw.swarm.SwarmVariable(surfaceLine.swarm, 'double', 2)\n",
    "uplithVisc = uw.swarm.SwarmVariable(surfaceLine.swarm, 'double', 1)\n",
    "uplithSr2Inv = uw.swarm.SwarmVariable(surfaceLine.swarm, 'double', 1)\n",
    "uplithVelX = uw.swarm.SwarmVariable(surfaceLine.swarm, 'double', 1)\n",
    "uplithStrainTens = uw.swarm.SwarmVariable(surfaceLine.swarm, 'double', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### fault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#the fault swarm will be positioned at faultLoc distance below the top of the slab, \n",
    "#intended to be between 0. and faultThickness\n",
    "#md.faultLocFac=0.\n",
    "\n",
    "faultLoc = md.faultLocFac*ndp.faultThickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#parallel safety\n",
    "if marker.swarm.particleCoordinates.data.shape[0]:\n",
    "    ds_depth = max(0.0, abs(faultLoc - ndp.faultThickness))\n",
    "    faultPoints = marker.swarm.particleCoordinates.data - marker.director.data[...]*ds_depth\n",
    "    faultPoints[:,1][faultPoints[:,1] >= 1.0] = 0.999999 #make sure no fault point have leaked through the top\n",
    "else:\n",
    "    faultPoints = np.array([[999999.,999999.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#ds = ndp.faultThickness\n",
    "#parallel safety\n",
    "if marker.swarm.particleCoordinates.data.shape[0]:\n",
    "    faultPoints = marker.swarm.particleCoordinates.data.copy()\n",
    "else:\n",
    "    faultPoints = np.array([[999999.,999999.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#fault thickness is thickness either side of fault.swarm\n",
    "\n",
    "fault = fault2D(mesh, velocityField, [], [], \n",
    "                ndp.faultThickness, ndp.frictionInterface, ndp.cohesionInterface, 1, insidePt=(-0.5,0.5))\n",
    "\n",
    "#*************CHECKPOINT-BLOCK**************#\n",
    "cp.addObject(fault.swarm,'fault')\n",
    "\n",
    "if not cp.restart:\n",
    "    if faultPoints.shape[0]:\n",
    "        fault.add_points(faultPoints[:, 0], faultPoints[:, 1])\n",
    "\n",
    "else:\n",
    "    fault.swarm.load(cp.loadpath + '/fault.h5')\n",
    "#*************CHECKPOINT-BLOCK**************#\n",
    "        \n",
    "fault.rebuild()\n",
    "fault.swarm.update_particle_owners()\n",
    "    \n",
    "    \n",
    "fault_coll = fault_collection([fault])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#for the initial condition\n",
    "\n",
    "\n",
    "def gaussian(x, mu, sig):\n",
    "    return np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def update_swarm_from_faults(faults, proximityVariable):\n",
    "    \"\"\"\n",
    "    Compute fault attributes from the marker-line objects in the 'faults' list.\n",
    "    Specifically:\n",
    "    \n",
    "      - proximityVariable carries information about which fault each swarm particle is close to (0 means none)\n",
    "      - normalVectorVariable maps the orientation of the fault to nearby swarm particles\n",
    "      - signedDistanceVariable carries the distance (positive means 'inside')  \n",
    "      \n",
    "      Unchecked error: if these variables are from different swarms \n",
    "      \n",
    "    \"\"\"\n",
    "    \n",
    "    for fault_seg in faults:\n",
    "\n",
    "        swarm = proximityVariable.swarm\n",
    "                \n",
    "        sd, pts0 = fault_seg.compute_signed_distance(swarm.particleCoordinates.data, distance=3.*fault_seg.thickness)\n",
    "        \n",
    "        effDist = 1. + 2.*gaussian( swarm.particleCoordinates.data[:,0], subZoneLoc.value + 0.5*thicknessAtTrench, thicknessAtTrench)\n",
    "        distMultiplier = 1./effDist\n",
    "        #insulate processors that have no fault\n",
    "        if sd.shape[0]:\n",
    "            sd[:,0]*=distMultiplier\n",
    "        \n",
    "\n",
    "        \n",
    "        proximityVariable.data[np.logical_and(sd<(ndp.faultThickness - faultLoc),sd>-1.*faultLoc)] = 1\n",
    "        \n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#proximityVariable.data[:] = 0.0\n",
    "#build the proximity \n",
    "if not cp.restart:\n",
    "    update_swarm_from_faults(fault_coll, proximityVariable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Setup a swarm to define the replacment positions\n",
    "\n",
    "allxs = np.arange(mesh.minCoord[0], mesh.maxCoord[0], ds_fault)[:-1]\n",
    "allys = (mesh.maxCoord[1] - faultLoc)*np.ones(allxs.shape)\n",
    "\n",
    "swarmTracerTop = uw.swarm.Swarm( mesh=mesh )\n",
    "dummy =  swarmTracerTop.add_particles_with_coordinates(np.column_stack((allxs, allys)))\n",
    "del allxs\n",
    "del allys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def update_swarm_from_faults(faults, proximityVariable):\n",
    "    \"\"\"\n",
    "    Compute fault attributes from the marker-line objects in the 'faults' list.\n",
    "    Specifically:\n",
    "    \n",
    "      - proximityVariable carries information about which fault each swarm particle is close to (0 means none)\n",
    "      - normalVectorVariable maps the orientation of the fault to nearby swarm particles\n",
    "      - signedDistanceVariable carries the distance (positive means 'inside')  \n",
    "      \n",
    "      Unchecked error: if these variables are from different swarms \n",
    "      \n",
    "    \"\"\"\n",
    "    \n",
    "    for fault_seg in faults:\n",
    "\n",
    "        swarm = proximityVariable.swarm\n",
    "        \n",
    "        #swarm = proximityVariable.swarm\n",
    "        sd, pts0 = fault_seg.compute_signed_distance(swarm.particleCoordinates.data, distance=3.*fault_seg.thickness)\n",
    "        #sp, pts0 = fault_seg.compute_marker_proximity(swarm.particleCoordinates.data)\n",
    "        \n",
    "        \n",
    "        proximityVariable.data[np.logical_and(sd<(ndp.faultThickness - faultLoc),sd>-1.*faultLoc)] = 1\n",
    "        \n",
    "        \n",
    "        #upper limit \n",
    "        faultUpLimFac = 2.0\n",
    "        proximityVariable.data[np.logical_or(sd>faultUpLimFac*(ndp.faultThickness - faultLoc),sd<-faultUpLimFac*faultLoc)] = 0\n",
    "\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#update_swarm_from_faults(fault_coll, proximityVariable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#fig= glucifer.Figure(quality=3)\n",
    "\n",
    "#fig.append( glucifer.objects.Surface(mesh, temperatureField ))\n",
    "#fig.append( glucifer.objects.Points(swarmTracerTop, pointSize=2))\n",
    "#fig.append( glucifer.objects.Points(swarm, proxyTempVariable,pointSize=2))\n",
    "#fig.append( glucifer.objects.Points(fault.swarm, pointSize=4))\n",
    "\n",
    "#fig.append( glucifer.objects.Points(slabLine.swarm, pointSize=4))\n",
    "#fig.append( glucifer.objects.Mesh(mesh))\n",
    "##\n",
    "#fig.show()\n",
    "#fig.save_database('test.gldb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Interpolate to temperature field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def swarmToTemp():\n",
    "\n",
    "    _ix, _weights, _dist = nn_evaluation(swarm.particleCoordinates.data, mesh.data, n=4, weighted=True)\n",
    "\n",
    "\n",
    "    #_dist.shape, mesh.data.shape\n",
    "    #if \n",
    "    tempMapTol = 0.2\n",
    "    tempMapMask = _dist.min(axis=1) < tempMapTol*(1. - mesh.minCoord[1])/mesh.elementRes[1] \n",
    "    \n",
    "    #temperatureField.data[:] = 0.\n",
    "    temperatureField.data[:] = ndp.potentialTemp #first set to dimensionless potential temp\n",
    "\n",
    "    #now used IDW to assign temp from particles to Field\n",
    "    #this is looking pretty ugly; nn_evaluation could use some grooming\n",
    "    temperatureField.data[:,0][tempMapMask] = np.average(proxyTempVariable.evaluate(swarm)[_ix][tempMapMask][:,:,0],weights=_weights[tempMapMask], axis=1)\n",
    "\n",
    "    #now cleanup any values that have fallen outside the Bcs\n",
    "\n",
    "    temperatureField.data[temperatureField.data > 1.] = ndp.potentialTemp\n",
    "    temperatureField.data[temperatureField.data < 0.] = 0.\n",
    "    \n",
    "    #and cleanup the BCs\n",
    "    \n",
    "    temperatureField.data[bWalls.data] = ndp.potentialTemp\n",
    "    temperatureField.data[tWalls.data] = 0.\n",
    "    \n",
    "    #if we're not imposing the rigdes, we want to leave these alone\n",
    "    if md.fixedRidges:\n",
    "        temperatureField.data[iWalls.data] = ndp.potentialTemp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#map proxy temp (swarm var) to mesh variable\n",
    "\n",
    "if not cp.restart:\n",
    "    swarmToTemp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#fig= glucifer.Figure(quality=3, boundingBox= bBox)\n",
    "\n",
    "#fig.append( glucifer.objects.Surface(mesh, slabCirc ))\n",
    "#fig.append( glucifer.objects.Points(swarm, proximityVariable, pointSize=2))\n",
    "#fig.append( glucifer.objects.Points(marker.swarm, pointSize=4))\n",
    "\n",
    "#\n",
    "#fig.show()\n",
    "#fig.save_database('test.gldb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#np.unique(proximityVariable.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#ndp.tempGradMantle\n",
    "#ndp.tempGradMantle\n",
    "#tempAtTrench "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#fig= glucifer.Figure(quality=3, boundingBox= bBox)\n",
    "\n",
    "#fig.append( glucifer.objects.Mesh(mesh ))\n",
    "#fig.append( glucifer.objects.Points(marker.swarm, pointSize=2))\n",
    "#fig.append( glucifer.objects.Points(slabLine.swarm, pointSize=2))\n",
    "\n",
    "#fig.append( glucifer.objects.Points(swarm, proxyTempVariable, pointSize=1))\n",
    "\n",
    "#fig.show()\n",
    "#fig.save_database('test.gldb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Swarm densification\n",
    "\n",
    "Try to build our initial geometry with less particles that are required dynamically, then use population_control to fill out the swarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "population_control = uw.swarm.PopulationControl(swarm, deleteThreshold=0.006, splitThreshold=0.25, maxDeletions=1, maxSplits=3, aggressive=True,aggressiveThreshold=0.9, particlesPerCell=int(md.ppc))\n",
    "\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def repopulate():\n",
    "    thresh = 5000.\n",
    "    diff = thresh + 1\n",
    "    count = 1\n",
    "    maxLoops = 10\n",
    "    pg = np.copy(swarm.particleGlobalCount)\n",
    "    while abs(diff) > thresh and count < maxLoops + 1:\n",
    "        population_control.repopulate()\n",
    "        diff = swarm.particleGlobalCount - pg\n",
    "        pg = swarm.particleGlobalCount\n",
    "        #print(str(count), str(pg), str(diff))\n",
    "        count += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#run repop function\n",
    "repopulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#((float(swarm.particleGlobalCount)/mesh.elementsGlobal))/md.ppc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## age variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#We'll also create a field to occompany the swarm var\n",
    "lithAgeField = uw.mesh.MeshVariable(mesh,nodeDofCount=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Now we'll set to zero the values, that aren't in the thermal lithosphere\n",
    "\n",
    "if not cp.restart:\n",
    "    ageVariable.data[:] =  proxyageFn.evaluate(swarm)\n",
    "\n",
    "dt_init = 0.\n",
    "\n",
    "\n",
    "lithAgeConds = fn.branching.conditional([(temperatureField < 0.9, (ageVariable + dt_init)), #idea is to make this arbitrarily complex\n",
    "                                         (True, 0.) ])\n",
    "\n",
    "\n",
    "\n",
    "ageVariable.data[:] = lithAgeConds.evaluate(swarm)\n",
    "\n",
    "del dt_init\n",
    "\n",
    "#Now define an minimum age for crust creation\n",
    "#ageCrustCreate = (5e6*(3600*24*365.))/sf.time\n",
    "ageCrustCreate = 0.1*ndp.slabMaxAge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ix1, weights1, d1 = nn_evaluation(swarm.particleCoordinates.data, mesh.data, n=5, weighted=True)\n",
    "    \n",
    "    \n",
    "#populate the mesh var. with an IDW interp.\n",
    "lithAgeField.data[:,0] =  np.average(ageVariable.evaluate(swarm)[:,0][ix1], weights=weights1, axis=len((weights1.shape)) - 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#fig= glucifer.Figure(quality=3, boundingBox= bBox)\n",
    "#fig.append( glucifer.objects.Surface(mesh,lithAgeField > ageCrustCreate))\n",
    "#fig.append( glucifer.objects.Points(swarm, materialVariable, pointSize=2))\n",
    "##fig.append( glucifer.objects.Points(surfaceLine.swarm, pointSize=2))\n",
    "\n",
    "#fig.show()\n",
    "#fig.save_database('test.gldb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#materialVariable.data[:] = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##  Material Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "###################\n",
    "#initial particle layout\n",
    "###################\n",
    "\n",
    "#Setup the graph object\n",
    "MG = MatGraph()\n",
    "\n",
    "#First thing to do is to add all the material types to the graph (i.e add nodes)\n",
    "MG.add_nodes_from(material_list)\n",
    "\n",
    "#mantle  => crust\n",
    "MG.add_transition((mantleID,crustID), depthFn, operator.lt, ndp.mantleCrustDepth)\n",
    "MG.add_transition((mantleID,crustID), lithAgeField, operator.gt, ageCrustCreate) #avoid crust near ridges\n",
    "MG.add_transition((mantleID,crustID), xFn, operator.lt, ndp.subZoneLoc)\n",
    "MG.add_transition((mantleID,crustID), xFn, operator.gt, mesh.minCoord[0]*0.8) #avoid crust near wall\n",
    "\n",
    "\n",
    "#crust  => mantle                \n",
    "MG.add_transition((crustID, mantleID), depthFn, operator.gt, ndp.interfaceDestroyDepth)\n",
    "\n",
    "MG.build_condition_list(materialVariable)\n",
    "\n",
    "if not cp.restart:\n",
    "    materialVariable.data[:] = fn.branching.conditional(MG.condition_list).evaluate(swarm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Final particle transformation rules\n",
    "#restrict crust creation - avoid crust on the upper plate\n",
    "\n",
    "MG.remove_edges_from([(mantleID,crustID)])\n",
    "\n",
    "#mantle  => crust\n",
    "MG.add_transition((mantleID,crustID), depthFn, operator.lt, ndp.mantleCrustDepth)\n",
    "MG.add_transition((mantleID,crustID), lithAgeField, operator.gt, ageCrustCreate)\n",
    "MG.add_transition((mantleID,crustID), xFn, operator.lt, (mesh.minCoord[0] - ndp.subZoneLoc)/2.)\n",
    "MG.add_transition((mantleID,crustID), xFn, operator.gt, mesh.minCoord[0]*0.8)\n",
    "\n",
    "MG.build_condition_list(materialVariable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## choose temp field to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if md.thermal:\n",
    "    temperatureFn = temperatureField\n",
    "else:\n",
    "    temperatureFn = proxyTempVariable\n",
    "    \n",
    "#This is not handled entirely consistnetly from here... need to rethink this\n",
    "\n",
    "#rebuild functions / clarify dependencies\n",
    "\n",
    "if md.thermal:\n",
    "    lithAgeConds = fn.branching.conditional([(temperatureFn < 0.9, (ageVariable)), #idea is to make this arbitrarily complex\n",
    "                                         (True, 0.) ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## adiabatic temp correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Adiabatic correction: this is added to the arrhenius laws to simulate the adiabatic component\n",
    "#We'll use a double linearisation of the adiabatic temp function:\n",
    "\n",
    "#ndp.tempGradMantle linearised at the mantle potential temp\n",
    "#dp.tempGradSlab linearised at typical slab temp\n",
    "\n",
    "\n",
    "tempAtTrench  = ndp.potentialTemp*math.erf((thicknessAtTrench)/(2.*math.sqrt(1.*ndp.slabMaxAge))) \n",
    "#this is the isotherm used to define the slab / mantle boundary, should be 0.9*Tp,\n",
    "\n",
    "\n",
    "adiabaticCorrectFn = fn.branching.conditional([(temperatureFn> tempAtTrench, depthFn*ndp.tempGradMantle), #idea is to make this arbitrarily complex\n",
    "                                      (True, depthFn*ndp.tempGradSlab) ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Also define the approx temp in C, for convenience \n",
    "tempCent = (temperatureFn+ adiabaticCorrectFn)*sf.deltaTemp\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Rheology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "symStrainrate = fn.tensor.symmetric( \n",
    "                            velocityField.fn_gradient )\n",
    "\n",
    "#Set up any functions required by the rheology\n",
    "strainRate_2ndInvariant = fn.tensor.second_invariant( \n",
    "                            fn.tensor.symmetric( \n",
    "                            velocityField.fn_gradient ))\n",
    "\n",
    "\n",
    "\n",
    "def safe_visc(func, viscmin=ndp.viscosityMin, viscmax=ndp.viscosityMax):\n",
    "    return fn.misc.max(viscmin, fn.misc.min(viscmax, func))\n",
    "\n",
    "\n",
    "\n",
    "#Add some portion of dynamic pressure to the depth-dependent Yield function\n",
    "#dynamicPressureProxyDepthFn = pressureField/ndp.rayleigh\n",
    "dynamicPressureProxyDepthFn = pressureField/sf.pressureDepthGrad\n",
    "\n",
    "druckerDepthFn = fn.misc.max(0.0, depthFn + md.druckerAlpha*(dynamicPressureProxyDepthFn))\n",
    "druckerFaultDepthFn = fn.misc.max(0.0, depthFn + md.druckerAlphaFault*(dynamicPressureProxyDepthFn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Diffusion Creep\n",
    "diffusionUM = (1./ndp.diffusionPreExp)*\\\n",
    "            fn.math.exp( ((ndp.diffusionEnergy + (depthFn*ndp.diffusionVolume))/((temperatureFn+ adiabaticCorrectFn + ndp.surfaceTemp))))\n",
    "\n",
    "diffusionLM = ndp.lowerMantleViscFac*(1./ndp.lowerMantlePreExp)*\\\n",
    "            fn.math.exp( ((ndp.lowerMantleEnergy + (depthFn*ndp.lowerMantleVolume))/((temperatureFn+ adiabaticCorrectFn + ndp.surfaceTemp))))\n",
    "\n",
    "viscosityLM = safe_visc(diffusionLM)\n",
    "\n",
    "#Add non-linearity\n",
    "viscosityUM0 = safe_visc(diffusionUM)\n",
    "\n",
    "if md.powerLaw:\n",
    "    powerLawSRFn= ((strainRate_2ndInvariant+ 1e-15)/ndp.powerLawStrain)**((1.-ndp.powerLawExp)/ndp.powerLawExp)\n",
    "    viscPower = viscosityUM0*powerLawSRFn\n",
    "    effviscosity = viscPower*viscosityUM0/(viscPower + viscosityUM0) #then combine harmonically\n",
    "    viscosityUM = safe_visc(effviscosity)\n",
    "\n",
    "else:\n",
    "    viscosityUM = viscosityUM0\n",
    "    \n",
    "#combine upper an lower mantle   \n",
    "mantleCreep = fn.branching.conditional( ((depthFn < ndp.lowerMantleDepth, viscosityUM ), \n",
    "                                           (True,                      diffusionLM )  ))\n",
    "\n",
    "\n",
    "#Define the mantle Plasticity\n",
    "ys =  ndp.cohesionMantle + (druckerDepthFn*ndp.frictionMantle)\n",
    "ysf = fn.misc.min(ys, ndp.yieldStressMax)\n",
    "yielding = ysf/(2.*(strainRate_2ndInvariant) + 1e-15) \n",
    "\n",
    "\n",
    "if md.viscCombine == 0:\n",
    "    mantleRheologyFn = safe_visc(fn.misc.min(mantleCreep, yielding), viscmin=ndp.viscosityMin, viscmax=ndp.viscosityMax)\n",
    "else:\n",
    "    mantleRheologyFn =  safe_visc(mantleCreep*yielding/(mantleCreep + yielding), viscmin=ndp.viscosityMin, viscmax=ndp.viscosityMax)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "normDepths = depthFn/ndp.refDepthInterface\n",
    "interfaceCreep = ndp.refViscInterface*fn.math.exp(ndp.logDelVisc*(1. - normDepths) )\n",
    "#interfaceCreep = safe_visc(interfaceCreep0, viscmin=ndp.viscosityMinInterface, viscmax= ndp.viscosityMaxInterface)\n",
    "\n",
    "#we want these avail. in all cases, as we evaluate it.\n",
    "interfaceys =  ndp.cohesionInterface + (druckerFaultDepthFn*ndp.frictionInterface)\n",
    "interfaceysf = fn.misc.min(interfaceys, ndp.ysMaxInterface)\n",
    "\n",
    "\n",
    "if ndp.viscosityMinInterface == ndp.viscosityMaxInterface: #isoviscous interface\n",
    "    interfaceViscosityFn = ndp.viscosityMinInterface\n",
    "    \n",
    "\n",
    "elif md.plasticInterface: #pseudo-brittle interface\n",
    "    interfaceYielding = interfaceysf/(2.*(strainRate_2ndInvariant) + 1e-15)\n",
    "    #combine\n",
    "    interfaceViscosityFn = safe_visc(fn.misc.min(interfaceCreep , interfaceYielding), viscmin=ndp.viscosityMinInterface, viscmax=ndp.viscosityMaxInterface)\n",
    "\n",
    "\n",
    "else: # a linear, brittle equivalent visc implementation\n",
    "    ndp.effStrainRate = ndp.subVelocity/ndp.faultThickness\n",
    "    effStressUpper =  ndp.cohesionInterface + (depthFn*ndp.frictionInterface)\n",
    "    interfaceYielding = effStressUpper/(2.*ndp.effStrainRate)\n",
    "    #combine\n",
    "    interfaceViscosityFn = safe_visc(fn.misc.min(interfaceCreep , interfaceYielding), viscmin=ndp.viscosityMinInterface, viscmax=ndp.viscosityMaxInterface)\n",
    "\n",
    "\n",
    "\n",
    "depthTaperFn = cosine_taper(depthFn, ndp.interfaceViscCutoffDepth, ndp.interfaceViscEndWidth)\n",
    "interfaceRheologyFn =  interfaceViscosityFn*(1. - depthTaperFn) + depthTaperFn*mantleRheologyFn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if md.interfaceType == 1:\n",
    "    viscosityMapFn = fn.branching.map( fn_key = materialVariable,\n",
    "                             mapping = {0:mantleRheologyFn,\n",
    "                                        1:interfaceRheologyFn} )\n",
    "\n",
    "elif md.interfaceType == 2:\n",
    "    viscosityMapFn = fn.branching.map( fn_key = proximityVariable,\n",
    "                             mapping = {0:mantleRheologyFn,\n",
    "                                        1:interfaceRheologyFn} )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Stokes vel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#viscMidMantle = diffusion.evaluate((ndp.leftLim + 1e-6, 1. - (200e3/sf.lengthScale)))\n",
    "#velStokes = ((2./9)/viscMidMantle)*ndp.rayleigh*thicknessAtTrench**2\n",
    "#fac = 100.*(365*24*3600)*(3.4482758620689656e-13)\n",
    "#velStokes*fac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## thermal,  phase and compositional buoyancy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Basic Thermal Density contrib.\n",
    "\n",
    "thermalDensityFn = ndp.rayleigh*(1. - temperatureFn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#Set up phase density contributions (approach of Yuen and Christenson)\n",
    "##############\n",
    "\n",
    "\n",
    "adibaticTempFn = temperatureFn + adiabaticCorrectFn\n",
    "buoyancyFactor = (dp.refGravity*sf.lengthScale**3)/(sf.viscosityScale*dp.refDiffusivity)\n",
    "slopeFactor = (dp.deltaTemp/(dp.refDensity*dp.refGravity*sf.lengthScale))\n",
    "\n",
    "\n",
    "#Scale the relavent dimensional parameters\n",
    "olDepths= np.array([410e3,660e3])/sf.lengthScale                  #depths of phase transitions along adiabat\n",
    "olTemps = (np.array([1600., 1900.]) - dp.surfaceTemp)/dp.deltaTemp   #temperatures of phase transitions along adiabat\n",
    "olWidths = np.array([10e3, 20e3])/sf.lengthScale                  #width if transition\n",
    "olClaps= np.array([2.5e6, -2.5e6])*slopeFactor             #Clapeyron slope of transition\n",
    "olBuoyancies= np.array([180., 400.])*buoyancyFactor       #Scaled buoyancy contributions\n",
    "\n",
    "\n",
    "\n",
    "#olivine\n",
    "olivinePhase = phases(name = 'ol', \n",
    "                        depths=olDepths,                  #depths of phase transitions along adiabat\n",
    "                        temps = olTemps,                  #temperatures of phase transitions along adiabat\n",
    "                        widths = olWidths,                #width if transition\n",
    "                        claps=olClaps,                    #Clapeyron slope of trnasition\n",
    "                        buoyancies = olBuoyancies)        #density change of phase transition\n",
    "\n",
    "\n",
    "olivine_phase_buoyancy = olivinePhase.buoyancy_sum(adibaticTempFn, depthFn)\n",
    "\n",
    "\n",
    "#Pyroxene/garnet\n",
    "#Scale the relavent dimensional parameters\n",
    "grtDepths = np.array([60e3,400e3,720e3])/sf.lengthScale            #depths of phase transitions along adiabat\n",
    "grtTemps = (np.array([ 1000., 1600., 1900.]) - dp.surfaceTemp)/dp.deltaTemp  #temperatures of phase transitions along adiabat\n",
    "grtWidths = np.array([ 10e3, 20e3, 20e3])/sf.lengthScale                  #width of transition\n",
    "grtClaps= np.array([ 0., 1.e6,  1e6])*slopeFactor             #Clapeyron slope of transition\n",
    "grtBuoyancies= np.array([350, 150., 400.])*buoyancyFactor       #Scaled buoyancy contributions\n",
    "\n",
    "\n",
    "\n",
    "garnetPhase = phases(name = 'grt', \n",
    "                        depths=grtDepths,                  #depths of phase transitions along adiabat\n",
    "                        temps = grtTemps,                  #temperatures of phase transitions along adiabat\n",
    "                        widths = grtWidths,                #width if transition\n",
    "                        claps=grtClaps,                    #Clapeyron slope of trnasition\n",
    "                        buoyancies = grtBuoyancies)        #density change of phase transition\n",
    "\n",
    "\n",
    "garnet_phase_buoyancy = garnetPhase.buoyancy_sum(adibaticTempFn, depthFn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#Set up compositional density contributions\n",
    "##############\n",
    "\n",
    "olivineSurfDensity = 3240.\n",
    "garnetSurfDensity =  3080.\n",
    "\n",
    "olivine_comp_buoyancy = (dp.refDensity - olivineSurfDensity)*buoyancyFactor\n",
    "garnet_comp_buoyancy = (dp.refDensity  - garnetSurfDensity)*buoyancyFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#Combine the density contributions\n",
    "##############\n",
    "\n",
    "olivineInBasalt = 0.0\n",
    "olivineInPyrolite = 0.6\n",
    "olivineInHarzburgite = 0.8\n",
    "\n",
    "#this is a crude way to adjust the buoyancies for models where the crust is thicker than physically accurate\n",
    "crustWidthBuoyFac = 7.5e3/dp.mantleCrustDepth\n",
    "\n",
    "basaltbuoyancyFn = thermalDensityFn  + \\\n",
    "                     crustWidthBuoyFac*(olivineInBasalt*(olivine_phase_buoyancy) + (1. - olivineInBasalt)*garnet_phase_buoyancy - \\\n",
    "                     olivineInBasalt* (olivine_comp_buoyancy) - (1. - olivineInBasalt)*garnet_comp_buoyancy)\n",
    "\n",
    "pyrolitebuoyancyFn = thermalDensityFn  + \\\n",
    "                     olivineInPyrolite*(olivine_phase_buoyancy) + (1. - olivineInPyrolite)*garnet_phase_buoyancy - \\\n",
    "                     olivineInPyrolite* (olivine_comp_buoyancy) - (1. - olivineInPyrolite)*garnet_comp_buoyancy\n",
    "\n",
    "harzbuoyancyFn = thermalDensityFn  + \\\n",
    "                     olivineInHarzburgite*(olivine_phase_buoyancy) + (1. - olivineInHarzburgite)*garnet_phase_buoyancy - \\\n",
    "                     olivineInHarzburgite* (olivine_comp_buoyancy) - (1. - olivineInHarzburgite)*garnet_comp_buoyancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#md.phaseBuoyancy = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if md.phaseBuoyancy:\n",
    "\n",
    "    densityMapFn = fn.branching.map( fn_key = materialVariable,\n",
    "                             mapping = {crustID:pyrolitebuoyancyFn, \n",
    "                                        mantleID:pyrolitebuoyancyFn} )\n",
    "\n",
    "else:\n",
    "    densityMapFn = fn.branching.map( fn_key = materialVariable,\n",
    "                             mapping = {crustID:thermalDensityFn, \n",
    "                                        mantleID:thermalDensityFn} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Now create a buoyancy force vector using the density and the vertical unit vector. \n",
    "\n",
    "gravity = ( 0.0, -1.0 )\n",
    "\n",
    "buoyancyMapFn = densityMapFn * gravity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Stokes system and solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got to Stokes\n"
     ]
    }
   ],
   "source": [
    "print('got to Stokes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'uw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2316551a348e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msurfaceArea\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIntegral\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmesh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmesh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mintegrationType\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'surface'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msurfaceIndexSet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtWalls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msurfacePressureIntegral\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIntegral\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpressureField\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmesh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmesh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mintegrationType\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'surface'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msurfaceIndexSet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtWalls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msmooth_pressure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmesh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpressure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# Smooths the pressure field.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'uw' is not defined"
     ]
    }
   ],
   "source": [
    "surfaceArea = uw.utils.Integral(fn=1.0,mesh=mesh, integrationType='surface', surfaceIndexSet=tWalls)\n",
    "surfacePressureIntegral = uw.utils.Integral(fn=pressureField, mesh=mesh, integrationType='surface', surfaceIndexSet=tWalls)\n",
    "\n",
    "NodePressure = uw.mesh.MeshVariable(mesh, nodeDofCount=1)\n",
    "Cell2Nodes = uw.utils.MeshVariable_Projection(NodePressure, pressureField, type=0)\n",
    "Nodes2Cell = uw.utils.MeshVariable_Projection(pressureField, NodePressure, type=0)\n",
    "\n",
    "def smooth_pressure(mesh):\n",
    "    # Smooths the pressure field.\n",
    "    # Assuming that pressure lies on the submesh, do a cell -> nodes -> cell\n",
    "    # projection.\n",
    "\n",
    "    Cell2Nodes.solve()\n",
    "    Nodes2Cell.solve()\n",
    "\n",
    "# a callback function to calibrate the pressure - will pass to solver later\n",
    "def pressure_calibrate():\n",
    "    (area,) = surfaceArea.evaluate()\n",
    "    (p0,) = surfacePressureIntegral.evaluate()\n",
    "    offset = p0/area\n",
    "    pressureField.data[:] -= offset\n",
    "    smooth_pressure(mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "stokesPIC = uw.systems.Stokes( velocityField  = velocityField, \n",
    "                                   pressureField  = pressureField,\n",
    "                                   conditions     = [freeslipBC,],\n",
    "                                   fn_viscosity   = viscosityMapFn, \n",
    "                                   fn_bodyforce   = buoyancyMapFn )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m\n",
      " \n",
      "Pressure iterations:   4\n",
      "Velocity iterations:   1 (presolve)      \n",
      "Velocity iterations:  -1 (pressure solve)\n",
      "Velocity iterations:   1 (backsolve)     \n",
      "Velocity iterations:   1 (total solve)   \n",
      " \n",
      "SCR RHS  solve time: 6.1430e-01\n",
      "Pressure solve time: 9.8819e-02\n",
      "Velocity solve time: 7.5736e-01 (backsolve)\n",
      "Total solve time   : 1.6038e+00\n",
      " \n",
      "Velocity solution min/max: 0.0000e+00/0.0000e+00\n",
      "Pressure solution min/max: 0.0000e+00/0.0000e+00\n",
      " \n",
      "\u001b[00m\n"
     ]
    }
   ],
   "source": [
    "solver = uw.systems.Solver(stokesPIC)\n",
    "\n",
    "\n",
    "if md.penaltyMethod:\n",
    "    solver.set_inner_method(\"mumps\")\n",
    "    solver.options.scr.ksp_type=\"cg\"\n",
    "    solver.set_penalty(1.0e7)\n",
    "    solver.options.scr.ksp_rtol = 1.0e-4\n",
    "\n",
    "else:\n",
    "    solver.options.main.Q22_pc_type='gkgdiag'\n",
    "    solver.options.scr.ksp_rtol=5e-5\n",
    "    solver.set_inner_method('mg')\n",
    "    solver.options.mg.levels = 4\n",
    "    \n",
    "    \n",
    "    \n",
    "#avoid this solve if restarting\n",
    "if not cp.restart:\n",
    "    solver.solve(nonLinearIterate=True, nonLinearTolerance=md.nltol, callback_post_solve = pressure_calibrate)\n",
    "    solver.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Now handled by the callback\n",
    "\n",
    "#Define an integral to remove drift in pressure\n",
    "#_pressure = surfint(pressureField)\n",
    "#_surfLength = surfint()\n",
    "#surfLength = _surfLength.evaluate()[0]\n",
    "\n",
    "##pressureSurf = _pressure.evaluate()[0]   \n",
    "#pressureField.data[:] -= pressureSurf/surfLength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#fig= glucifer.Figure(quality=3)\n",
    "\n",
    "#fig.append( glucifer.objects.Mesh(mesh, opacity=0.2))\n",
    "#fig.append( glucifer.objects.Points(swarm, dynamicPressureProxyDepthFn + depthFn, pointSize=2))\n",
    "#fig.append( glucifer.objects.Points(swarm, proxyTempVariable, pointSize=2))\n",
    "\n",
    "#fig.append( glucifer.objects.Points(marker.swarm,  pointSize=2))\n",
    "\n",
    "#fig.append( glucifer.objects.VectorArrows(mesh, velocityField, arrowHead=1, scaling=0.00005))\n",
    "#fig.append( glucifer.objects.Surface(mesh,pyrolitebuoyancyFn ))\n",
    "#fig.show()\n",
    "#fig.save_database('test.gldb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Setup advection-diffusion, swarm advection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "advector = uw.systems.SwarmAdvector( swarm=swarm, velocityField=velocityField, order=2 )\n",
    "\n",
    "\n",
    "\n",
    "#test using temperatureFn, rather than field here (depends on how pointers work)\n",
    "if md.thermal:\n",
    "    advDiff = uw.systems.AdvectionDiffusion( phiField       = temperatureFn, \n",
    "                                         phiDotField    = temperatureDotField, \n",
    "                                         velocityField  = velocityField,\n",
    "                                         fn_sourceTerm    = 0.0,\n",
    "                                         fn_diffusivity = 1., \n",
    "                                         #conditions     = [neumannTempBC, dirichTempBC] )\n",
    "                                         conditions     = [ dirichTempBC] )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Initial thermal diffusion\n",
    "\n",
    "Working, but not tuned or tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if md.diffuseInitial and md.thermal:\n",
    "\n",
    "    velocityField0   = uw.mesh.MeshVariable( mesh=mesh,         nodeDofCount=2 )\n",
    "    velocityField0.data[:] = 0.0\n",
    "\n",
    "    #testDepth = 50e3/sf.lengthScale\n",
    "    #testWidth = 10e3/sf.lengthScale \n",
    "\n",
    "    #difftanhFn = 0.5*(fn.math.tanh((depthFn - testDepth)/(testWidth))) + 0.5\n",
    "\n",
    "\n",
    "    advDiff0 = uw.systems.AdvectionDiffusion( phiField       = temperatureFn, \n",
    "                                             phiDotField    = temperatureDotField, \n",
    "                                             velocityField  = velocityField0,\n",
    "                                             fn_sourceTerm    = 0.0,\n",
    "                                             fn_diffusivity = 1.0, \n",
    "                                             #conditions     = [neumannTempBC, dirichTempBC] )\n",
    "                                             conditions     = [ dirichTempBC] )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    diff_for  = md.diffuseInitial*(3600.*365.*24.)/sf.time\n",
    "    dt_diff = 0.\n",
    "    step_diff = 0.\n",
    "    while dt_diff < diff_for:\n",
    "        dt_now = advDiff0.get_max_dt()\n",
    "        advDiff0.integrate(dt_now)\n",
    "        dt_diff += dt_now\n",
    "        step_diff += 1\n",
    "        print('years and step: {} {}'.format((dt_diff*sf.time)/(3600.*365.*24.), step_diff))   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "past first solve\n"
     ]
    }
   ],
   "source": [
    "print('past first solve')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## More functions and fields\n",
    "\n",
    "For integration, querying, plotting, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#fields / mesh variables\n",
    "\n",
    "stressFieldX    = uw.mesh.MeshVariable( mesh=mesh,         nodeDofCount=1 )\n",
    "stressFieldMag    = uw.mesh.MeshVariable( mesh=mesh,         nodeDofCount=1 )\n",
    "proximityField = uw.mesh.MeshVariable( mesh=mesh,         nodeDofCount=1 )\n",
    "#restrictionFnField = uw.mesh.MeshVariable( mesh=mesh,         nodeDofCount=1 )\n",
    "eig1       = uw.mesh.MeshVariable( mesh=mesh,         nodeDofCount=2 )\n",
    "eig2       = uw.mesh.MeshVariable( mesh=mesh,         nodeDofCount=2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Setup any extra uw fucntions and handles to evaluate\n",
    "\n",
    "sinner = fn.math.dot( strainRate_2ndInvariant, strainRate_2ndInvariant )\n",
    "\n",
    "vd = 4.*viscosityMapFn*sinner #there's an extra factor of 2, which is necessary because the of factor of 0.5 in the UW second invariant \n",
    "vx = velocityField[0]\n",
    "\n",
    "#density function here is okay, as |g| = 1\n",
    "dw = thermalDensityFn*velocityField[1] #if compositional buoyancy is added, we'll need to add the the proper Buoyancy Fn\n",
    "\n",
    "\n",
    "sym_strainRate = fn.tensor.symmetric( \n",
    "                            velocityField.fn_gradient )\n",
    "\n",
    "stressXVariableFn =  2.*sym_strainRate[0]*viscosityMapFn\n",
    "stressMagVariableFn =  2.*strainRate_2ndInvariant*viscosityMapFn\n",
    "\n",
    "if md.thermal:\n",
    "    dTdZ = temperatureFn.fn_gradient[1]\n",
    "else:\n",
    "    dTdZ = fn.misc.constant(1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Values and metrics\n",
    "\n",
    "Mostly, this consists of integral and min/max values. \n",
    "\n",
    "The most challenging part is defining restricted domains for these calculations.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Setup integral domain / restriction functions\n",
    "\n",
    "\n",
    "#0 - these ones are used in tracking the movement of plates Tres Importantee\n",
    "#at each step, out plate boundary search will happen in these limits only\n",
    "pbbound = 150e3/sf.lengthScale\n",
    "pbwidth = 10e3/sf.lengthScale\n",
    "szRfn150 = 1. - cosine_taper(fn.math.abs(xFn - subZoneLoc),pbbound, pbwidth)\n",
    "szRfn300 = 1. - cosine_taper(fn.math.abs(xFn - subZoneLoc),2*pbbound, pbwidth)\n",
    "\n",
    "spRidgeRfn = 1. - cosine_taper(fn.math.abs(xFn - spRidgeLoc),pbbound, pbwidth)\n",
    "opRidgeRfn = 1. - cosine_taper(fn.math.abs(xFn - opRidgeLoc),pbbound, pbwidth)\n",
    "\n",
    "#1\n",
    "#Level 3. thermal lithosphere - mantle:\n",
    "lithconditions = [ (         temperatureFn < 0.9,  1.),\n",
    "                   (                                                   True , 0.) ]\n",
    "lithTempRFn = fn.branching.conditional(lithconditions)\n",
    "\n",
    "#2 \n",
    "upMantleconditions = [ (         depthFn < ndp.lowerMantleDepth,  1.),\n",
    "                   (                                                   True , 0.) ]\n",
    "\n",
    "upMantleRfn = fn.branching.conditional(upMantleconditions)\n",
    "\n",
    "#3\n",
    "lowMantleconditions = [ (         depthFn > ndp.lowerMantleDepth,  1.),\n",
    "                   (                                                   True , 0.) ]\n",
    "\n",
    "lowMantleRfn = fn.branching.conditional(lowMantleconditions)\n",
    "\n",
    "#5\n",
    "\n",
    "MantleSlabConditions = [ (operator.and_((lithTempRFn > 0.5),(depthFn > ndp.lowerMantleDepth)) , 1.),\n",
    "                        (                                                   True , 0.) ]\n",
    "\n",
    "lowMantleSlabRfn = fn.branching.conditional(MantleSlabConditions)\n",
    "\n",
    "#5\n",
    "\n",
    "#also add RMS for the lithosphere, or some measure of relative subduction rate\n",
    "velLimitX = 1./50. #these will need tuning!\n",
    "velLimitY = 1./50.\n",
    "velXNorm = velocityField[0]/ndp.subVelocity\n",
    "velYNorm = velocityField[1]/ndp.subVelocity\n",
    "\n",
    "lowPlateConditions = [ (           operator.and_( operator.and_((depthFn < thicknessAtTrench), (lithTempRFn > 0.5)),  (velXNorm> -1.0*velLimitX)), 1.),\n",
    "                       (operator.and_((lithTempRFn > 0.5),(velYNorm < -1*velLimitY))  , 1.),\n",
    "                       (operator.and_((depthFn > thicknessAtTrench), (lithTempRFn > 0.5)),1.),\n",
    "                       (                                                   True , 0.) ]\n",
    "\n",
    "lowPlateRfn = fn.branching.conditional(lowPlateConditions)\n",
    "\n",
    "\n",
    "#6\n",
    "\n",
    "lowPlateBendingConds = [ (operator.and_((lowPlateRfn > 0.5),(depthFn < (300e3/sf.lengthScale))) , 1.),\n",
    "                        (                                                   True , 0.) ]\n",
    "\n",
    "lowPlateBendingRfn = fn.branching.conditional(lowPlateBendingConds)\n",
    "\n",
    "\n",
    "\n",
    "#7\n",
    "if md.interfaceType == 2:\n",
    "    interfaceConds = [ (operator.and_((proximityVariable > 0.9), (proximityVariable < 1.1)), 1.),\n",
    "                        (                                                   True , 0.) ]\n",
    "    interfaceRfn0 = fn.branching.conditional(interfaceConds)\n",
    "else:\n",
    "\n",
    "    interfaceConds = [ (operator.and_((materialVariable > 0.9), (materialVariable < 1.1)), 1.),\n",
    "                        (                                                   True , 0.) ]\n",
    "    interfaceRfn0 = fn.branching.conditional(interfaceConds)\n",
    "\n",
    "#also limit the depth for the interface integrals\n",
    "interfaceDepthLimitConds = [ (depthFn < 150e3, 1.),\n",
    "                        (                                                   True , 0.) ]\n",
    "interfaceDepthLimitFn = fn.branching.conditional(interfaceDepthLimitConds)\n",
    " \n",
    "interfaceRfn = interfaceDepthLimitFn*interfaceRfn0\n",
    "\n",
    "#8 , a function that should exclude all mantle except the wedge\n",
    "#This is based on a straight line that starts 50 km arcward of the trench, and with a slope of -0.75\n",
    "#but should be flexible enough the majority of slab dips\n",
    "wedgeConds = [ (depthFn > 250e3/sf.lengthScale, 0.0),\n",
    "               (xFn > subZoneLoc + 400e3/sf.lengthScale, 0.0),\n",
    "                                         ( coordinate[1] > 1. - 0.75*(xFn - (subZoneLoc + 50e3/sf.lengthScale)), 1.0),\n",
    "                        (                                                   True , 0.) ]\n",
    "wedgeRFn = fn.branching.conditional(wedgeConds)\n",
    "\n",
    "\n",
    "#This is same domain as the function we use to evaluate the location of the hot corner\n",
    "#This one has binary values intended for integration\n",
    "critWedgeTempIntConds = [ (operator.and_(wedgeRFn > 0.5,tempCent > 1250. ), 1.0),\n",
    "                        (                                                   True , 0.) ]\n",
    "critWedgeTempIntFn = fn.branching.conditional(critWedgeTempIntConds)\n",
    "\n",
    "\n",
    "\n",
    "#10 - these ones divide up the system domain into plates (assuming < 4 plate system)\n",
    "\n",
    "#Always use operator! np.logical_and is not trustworthy when applied to uw functions\n",
    "#spPlateConds = [ (    operator.and_( xFn >  spRidgeLoc, xFn <  subZoneLoc),  1.),\n",
    "#                   (                                                   True , 0.) ]\n",
    "#spPlateFn = fn.branching.conditional(spPlateConds)\n",
    "\n",
    "#opPlateConds =  [ (    operator.and_( xFn >  subZoneLoc, xFn <  opRidgeLoc),  1.),\n",
    "#                   (                                                   True , 0.) ]\n",
    "#opPlateFn = fn.branching.conditional(opPlateConds)\n",
    "\n",
    "#movingPlatesConds =  [ (    operator.and_( xFn >  spRidgeLoc, xFn <  opRidgeLoc),  1.),\n",
    "#                   (                                                   True , 0.) ]\n",
    "#movingPlatesFn = fn.branching.conditional(movingPlatesConds)\n",
    "\n",
    "\n",
    "#sig = 15e3/sf.lengthScale #We'll use this to fix inf values that can occur at domain boundaries\n",
    "#fixedridgeFn = 1. -  \\\n",
    "#                fn.math.exp(-1.*(xFn - mesh.minCoord[0])**2/(2 * sig**2))- \\\n",
    "#                fn.math.exp(-1.*(xFn - mesh.maxCoord[0])**2/(2 * sig**2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#fig= glucifer.Figure(quality=3, boundingBox= bBox)\n",
    "#fig.append( glucifer.objects.Surface(mesh, wedgeRFn))\n",
    "#fig.append( glucifer.objects.Contours(mesh, temperatureFn ))\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Setup integrals \n",
    "\n",
    "_dwint = volumeint(dw,1.)\n",
    "_nuTop = surfint(dTdZ)\n",
    "\n",
    "\n",
    "_tempint = volumeint(temperatureField)\n",
    "\n",
    "\n",
    "_areaintcritWedgeTemp  = volumeint(critWedgeTempIntFn)\n",
    "\n",
    "_areaintLith  = volumeint(lithTempRFn)\n",
    "_vdintLith  = volumeint(vd,lithTempRFn)\n",
    "\n",
    "_areaintLower  = volumeint(lowPlateRfn)\n",
    "_vdintLower  = volumeint(vd,lowPlateRfn)\n",
    "\n",
    "_areaintLowerBending  = volumeint(lowPlateBendingRfn)\n",
    "_vdintLowerBending  = volumeint(vd,lowPlateBendingRfn)\n",
    "\n",
    "#_areaintUM  = volumeint(upMantleRfn)\n",
    "_vdintUM  = volumeint(vd,upMantleRfn)\n",
    "\n",
    "#_areaintLM  = volumeint(lowMantleRfn)\n",
    "_vdintLM  = volumeint(vd,lowMantleRfn)\n",
    "\n",
    "_areaintSlabLM  = volumeint(lowMantleSlabRfn)\n",
    "_vdintSlabLM  = volumeint(vd,lowMantleSlabRfn)\n",
    "\n",
    "_areaintInterface  = volumeint(interfaceRfn)\n",
    "_vdintInterface = volumeint(vd,interfaceRfn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#'_mmVxSurfNearLeft'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Setup max min fns \n",
    "\n",
    "#Surface extrema\n",
    "_mmVxSurf = fn.view.min_max(vx)\n",
    "dummyFn = _mmVxSurf.evaluate(tWalls)\n",
    "\n",
    "#These ones are used to track plate boundaries\n",
    "_szVelGrads = fn.view.min_max(sym_strainRate[0]*szRfn150, fn_auxiliary=xFn)\n",
    "dummyFn = _szVelGrads.evaluate(tWalls)\n",
    "\n",
    "_spRidgeVelGrads = fn.view.min_max(sym_strainRate[0]*spRidgeRfn, fn_auxiliary=xFn)\n",
    "dummyFn = _spRidgeVelGrads.evaluate(tWalls)\n",
    "\n",
    "_opRidgeVelGrads = fn.view.min_max(sym_strainRate[0]*opRidgeRfn, fn_auxiliary=xFn)\n",
    "dummyFn = _opRidgeVelGrads.evaluate(tWalls)\n",
    "\n",
    "#Misc\n",
    "\n",
    "#this is used to build the location of the hot (meltable) mantle in wedge\n",
    "critWedgeTempConds = [ (operator.and_(wedgeRFn > 0.5,tempCent > 1250. ), xFn),\n",
    "                        (                                                   True , 10.) ]\n",
    "critWedgeTempFn = fn.branching.conditional(critWedgeTempConds)\n",
    "\n",
    "_wedgeHotCorner = fn.view.min_max(critWedgeTempFn, fn_auxiliary=coordinate)\n",
    "dummyFn = _wedgeHotCorner.evaluate(mesh)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#import glucifer\n",
    "#fig= glucifer.Figure(quality=3)\n",
    "#\n",
    "#fig.append( glucifer.objects.Surface(mesh, critWedgeTempFn ))\n",
    "#fig.append( glucifer.objects.Points(swarm, proximityVariable, pointSize=2))\n",
    "#fig.append( glucifer.objects.Points(marker.swarm, pointSize=4))\n",
    "#fig.append( glucifer.objects.Points(fault.swarm, pointSize=4))\n",
    "#fig.append( glucifer.objects.Mesh(mesh))\n",
    "##\n",
    "#fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Build a depth dependent mask for the vizualisation\n",
    "\n",
    "depthVariable      = swarm.add_variable( dataType=\"float\", count=1 )\n",
    "depthVariable.data[:] = depthFn.evaluate(swarm)\n",
    "\n",
    "vizVariable      = swarm.add_variable( dataType=\"int\", count=1 )\n",
    "vizVariable.data[:] = 0\n",
    "\n",
    "for index, value in enumerate(depthVariable.data[:]):\n",
    "    #print index, value\n",
    "    if np.random.rand(1)**30 > value/(mesh.maxCoord[1] - mesh.minCoord[1]):\n",
    "        vizVariable.data[index] = 1\n",
    "    #if value > 660e3/sf.lengthScale:\n",
    "    #    vizVariable.data[index] = 0\n",
    "        \n",
    "        \n",
    "del index, value    #get rid of any variables that might be pointing at the .data handles (these are!)\n",
    "\n",
    "#Now randomly cull more particles if desired\n",
    "\n",
    "removeRandom = True\n",
    "if removeRandom:\n",
    "    reducFac = 0.6  #0.9 > remove 90%\n",
    "    nonzs = np.where(vizVariable.data[:,0] == 1)[0].copy()\n",
    "    nstart =  nonzs.shape[0]\n",
    "    nend = int(np.ceil(nstart*reducFac))\n",
    "    np.random.shuffle(nonzs)\n",
    "    nstart, nend\n",
    "\n",
    "    vizVariable.data[nonzs[:nend]] = 0\n",
    "    del nonzs, nstart, nend\n",
    "\n",
    "\n",
    "\n",
    "#Build any Functions we need for Viz\n",
    "\n",
    "stressII = 2.*strainRate_2ndInvariant*viscosityMapFn\n",
    "stressXX = 2.*symStrainrate[0]*viscosityMapFn\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Set up the gLucifer stores\n",
    "\n",
    "fullpath = os.path.join(outputPath + \"gldbs/\")\n",
    "store1 = glucifer.Store(fullpath + 'subduction1.gldb')\n",
    "store2 = glucifer.Store(fullpath + 'subduction2.gldb')\n",
    "store3 = glucifer.Store(fullpath + 'subduction3.gldb')\n",
    "store4 = glucifer.Store(fullpath + 'subduction4.gldb')\n",
    "store5 = glucifer.Store(fullpath + 'subduction5.gldb')\n",
    "store6 = glucifer.Store(fullpath + 'subduction6.gldb')\n",
    "\n",
    "fig1 = glucifer.Figure(store1,figsize=(300*np.round(md.aspectRatio,2),300))\n",
    "if md.thermal:\n",
    "    fig1.append( glucifer.objects.Points(swarm, temperatureFn, pointSize=2,  valueRange=[0.0, 1.0], fn_mask=vizVariable))\n",
    "else:\n",
    "    fig1.append( glucifer.objects.Points(swarm, proxyTempVariable, pointSize=2, valueRange=[0.0, 1.0],  fn_mask=vizVariable))\n",
    "fig1.append( glucifer.objects.Points(fault.swarm, pointSize=5, colourBar=False))\n",
    "\n",
    "\n",
    "fig2 = glucifer.Figure(store2,figsize=(300*np.round(md.aspectRatio,2),300))\n",
    "fig2.append( glucifer.objects.Points(swarm, viscosityMapFn, pointSize=2, fn_mask=vizVariable, logScale=True, valueRange=[100.*ndp.viscosityMin, ndp.viscosityMax]))\n",
    "fig2.append( glucifer.objects.VectorArrows(mesh, velocityField, arrowHead=1, scaling=0.00005))\n",
    "\n",
    "\n",
    "fig3 = glucifer.Figure(store3,figsize=(300*np.round(md.aspectRatio,2),300))\n",
    "fig3.append( glucifer.objects.Points(swarm, pressureField, pointSize=2, fn_mask=vizVariable))\n",
    "fig3.append( glucifer.objects.Mesh(mesh))\n",
    "\n",
    "fig3.append( glucifer.objects.Points(marker.swarm, pointSize=5, colourBar=False))\n",
    "\n",
    "\n",
    "fig4 = glucifer.Figure(store4,figsize=(300*np.round(md.aspectRatio,2),300))\n",
    "fig4.append( glucifer.objects.Surface(mesh, lithAgeField ))\n",
    "fig4.append( glucifer.objects.Surface(mesh, critWedgeTempFn))\n",
    "fig4.append( glucifer.objects.Surface(mesh, szRfn150))\n",
    "\n",
    "\n",
    "if md.thermal:\n",
    "    fig4.append( glucifer.objects.Surface(mesh, lowPlateRfn ))\n",
    "fig4.append( glucifer.objects.Points(fault.swarm, pointSize=5, colourBar=False))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig5 = glucifer.Figure(store5,figsize=(300*np.round(md.aspectRatio,2),300))\n",
    "fig5.append( glucifer.objects.Points(swarm, stressII , pointSize=2, fn_mask=vizVariable, valueRange=[0.0,ndp.yieldStressMax]))\n",
    "fig5.append( glucifer.objects.Points(swarm, stressXX , pointSize=2, fn_mask=vizVariable, valueRange=[-1*ndp.yieldStressMax/2.,ndp.yieldStressMax/2.]))\n",
    "#fig5.append(glucifer.objects.Contours(mesh, temperatureField))\n",
    "\n",
    "fig6 = glucifer.Figure(store6,figsize=(300*np.round(md.aspectRatio,2),300))\n",
    "if md.interfaceType==2:\n",
    "    fig6.append( glucifer.objects.Points(swarm, proximityVariable, pointSize=2, fn_mask=vizVariable))\n",
    "else:\n",
    "    fig6.append( glucifer.objects.Points(swarm, materialVariable, pointSize=2, fn_mask=vizVariable))\n",
    "fig6.append( glucifer.objects.Points(fault.swarm, pointSize=5, colourBar=False))\n",
    "fig6.append( glucifer.objects.Points(swarm, materialVariable, pointSize=2, fn_mask=vizVariable))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Update functions for main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def main_update(next_image_step):\n",
    "    \n",
    "    \"\"\"\n",
    "    This includes some functionality for image / file writing at speciified time intervals,\n",
    "    Assumes global variables:\n",
    "        time, step, files_freq, next_image_step\n",
    "    \n",
    "    if numerical dt exceeds next specified writing point\n",
    "    override dt make sure we hit that point\n",
    "    Set some flags so that image / file writing proceeds\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    if md.thermal:\n",
    "        dt = advDiff.get_max_dt()*md.courantFac #additional md.courantFac helps stabilise advDiff\n",
    "        advDiff.integrate(dt)\n",
    "        \n",
    "    else:\n",
    "        dt = advector.get_max_dt()\n",
    "        \n",
    "    #This relates to file writing at set period:\n",
    "    #override dt make sure we hit certain time values\n",
    "    #Set some flags so that image / file writing proceeds\n",
    "    \n",
    "    if step == 0:\n",
    "        files_this_step = True\n",
    "    else:\n",
    "        files_this_step = False\n",
    "    \n",
    "    if time + dt >= next_image_step:\n",
    "        dt = next_image_step - time\n",
    "        files_this_step = True\n",
    "        next_image_step += files_freq #increment time for our next image / file dump\n",
    "        \n",
    "        \n",
    "    #Do advection\n",
    "    #I inlude marker swarms here, so their tailored update functions don't havre to be run every time step\n",
    "    \n",
    "    advector.integrate(dt)\n",
    "    marker.advection(dt)\n",
    "    fault.advection(dt)\n",
    "    \n",
    "    #Now handled by the solver callback\n",
    "    #remove drift in pressure\n",
    "    #pressureSurf = _pressure.evaluate()[0]   \n",
    "    #pressureField.data[:] -= pressureSurf/surfLength\n",
    "    \n",
    "    \n",
    "    return time+dt, step+1,dt, files_this_step, next_image_step\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int32)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataToadd = np.empty((0,2)).astype(int) #a dummy array\n",
    "    \n",
    "    \n",
    "#Add any particles that remain\n",
    "fault.swarm.add_particles_with_coordinates(dataToadd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def fault_update():\n",
    "    \n",
    "    \"\"\"\n",
    "    Assumes global variables:\n",
    "    \n",
    "    * dt\n",
    "    * ndp.interfaceDestroyDepth\n",
    "    * sf.lengthScale\n",
    "    * lithAgeField\n",
    "    * ds_fault             #fault particle spacing\n",
    "    * md.swarmUpdate\n",
    "    * subZoneLoc (not ndp.subZoneLoc)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #reset to zero\n",
    "    #proximityVariable.data[:,:] = 0.0\n",
    "  \n",
    "    #First, we'll try to add particles back in...\n",
    "    #a number of constraints are placed on which ones we choose\n",
    "    \n",
    "    #avoid particles which already hit the proximity region (field)\n",
    "    #newMask1 = np.where(\n",
    "    #    proximityField.evaluate(np.column_stack(\n",
    "    #        (swarmTracerTop.particleCoordinates.data[:,0], swarmTracerTop.particleCoordinates.data[:,1] + 0.49*faultLoc ))\n",
    "    #                           )[:,0] == 0)[0]\n",
    "    \n",
    "    #remove particles in prohibited regions\n",
    "   \n",
    "    if swarmTracerTop.particleCoordinates.data.shape[0]:\n",
    "        newMask1 = np.where(swarmTracerTop.particleCoordinates.data[:,0] < (subZoneLoc.value - 150e3/sf.lengthScale))[0]\n",
    "    \n",
    "        #remove particles that are nearby to existing ones (ds_fault is the expected distance between fault points)\n",
    "        if not fault.empty:\n",
    "            ds, ids =  fault.kdtree.query(swarmTracerTop.particleCoordinates.data)\n",
    "            #This should not aim to to perform regular partical addition, hence factor of 4\n",
    "            #otherwise, can two horizontal layers forming\n",
    "            newMask2 = np.where(ds > 4*ds_fault)[0]\n",
    "\n",
    "            totesMask = np.intersect1d(newMask1, newMask2)\n",
    "        #if there is no fault locally, we don't need to check\n",
    "        else:\n",
    "            totesMask = newMask1\n",
    "\n",
    "        dataToadd = swarmTracerTop.particleCoordinates.data[totesMask, :]\n",
    "\n",
    "    else:\n",
    "        dataToadd = np.empty((0,2)).astype(int) #a dummy array\n",
    "    \n",
    "    #Add any particles that remain\n",
    "    fault.swarm.add_particles_with_coordinates(dataToadd)\n",
    "    \n",
    "    #cull any below cutoff depth\n",
    "    cutoffDepth = ndp.interfaceViscCutoffDepth + ndp.interfaceViscEndWidth\n",
    "    depthMask1 = np.where(fault.swarm.particleCoordinates.data[:,1] < (mesh.maxCoord[1] - cutoffDepth))[0]\n",
    "    \n",
    "    with fault.swarm.deform_swarm():\n",
    "        fault.swarm.particleCoordinates.data[depthMask1] = (999999.,999999.)\n",
    "    \n",
    "    uw.barrier()\n",
    "    \n",
    "    #and any particles where the age is too young - aimed at reducing the fault interacting with the MOR.\n",
    "    if fault.swarm.particleCoordinates.data.shape[0]:\n",
    "        ageMask = np.where(lithAgeField.evaluate(fault.swarm) < ageCrustCreate)[0]\n",
    "    else:\n",
    "        ageMask = np.empty(0, dtype=np.bool)\n",
    "    with fault.swarm.deform_swarm():\n",
    "        fault.swarm.particleCoordinates.data[ageMask] = (999999.,999999.)\n",
    "        \n",
    "        \n",
    "    #Reset any particles beneath interface reset depth\n",
    "    #i.e. we don't let proximity 'accumulate beneath this depth'\n",
    "    \n",
    "    depthMask2 = np.where(swarm.particleCoordinates.data[:,1] < (1. - ndp.interfaceResetDepth))\n",
    "    proximityVariable.data[depthMask2] = 0\n",
    "        \n",
    "    \n",
    "    #now we can rebuild the fault\n",
    "    fault.rebuild()\n",
    "    update_swarm_from_faults(fault_coll, proximityVariable)\n",
    "    \n",
    "    #for any particles deeper than ndp.interfaceDestroyDepth, proximity goes to zero as well\n",
    "    \n",
    "    depthMask3 = np.where(swarm.particleCoordinates.data[:,1] < (1. - ndp.interfaceDestroyDepth))\n",
    "    proximityVariable.data[depthMask3] = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#dt = 0.00001\n",
    "#fault_update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def age_update():\n",
    "    \n",
    "    \"\"\"\n",
    "    update age variable which requires some special attention\n",
    "    Assumes global variables:\n",
    "    \n",
    "    * dt\n",
    "    * step \n",
    "    \"\"\"\n",
    "    \n",
    "    #this one run whether the model is thermal or not\n",
    "    # (although the lithAgeField will have less meaning for the compositional model )\n",
    "    \n",
    "    #then we increment the age everwhere\n",
    "    ageVariable.data[:]+=dt\n",
    "    \n",
    "    #occasionally reset\n",
    "    if md.thermal:\n",
    "        if step%10==0:\n",
    "            ageVariable.data[:] = lithAgeConds.evaluate(swarm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def viz_update():\n",
    "    \n",
    "    #Rebuild the viz. mask\n",
    "    vizVariable.data[:] = 0\n",
    "\n",
    "    for index, value in enumerate(depthVariable.data[:]):\n",
    "        #print index, value\n",
    "        if np.random.rand(1)**5 > value/(mesh.maxCoord[1] - mesh.minCoord[1]):\n",
    "            vizVariable.data[index] = 1\n",
    "\n",
    "    del index, value    #get rid of any variables that might be pointing at the .data handles (these \n",
    "    \n",
    "    if removeRandom:\n",
    "        reducFac = 0.6  #0.9 > remove 90%\n",
    "        nonzs = np.where(vizVariable.data[:,0] == 1)[0].copy()\n",
    "        nstart =  nonzs.shape[0]\n",
    "        nend = int(np.ceil(nstart*reducFac))\n",
    "        np.random.shuffle(nonzs)\n",
    "        nstart, nend\n",
    "\n",
    "        vizVariable.data[nonzs[:nend]] = 0\n",
    "        del nonzs, nstart, nend   \n",
    "    \n",
    "    #save gldbs\n",
    "    fullpath = os.path.join(outputPath + \"gldbs/\")\n",
    "    \n",
    "    store1.step = step\n",
    "    fig1.save( fullpath + \"Temp\" + str(step).zfill(5))\n",
    "    \n",
    "    store2.step = step\n",
    "    fig2.save( fullpath + \"visc\" + str(step).zfill(5))\n",
    "    \n",
    "    #store3.step = step\n",
    "    #fig3.save( fullpath + \"pressure\" + str(step).zfill(5))\n",
    "    \n",
    "    store4.step = step\n",
    "    fig4.save( fullpath + \"age_lith\" + str(step).zfill(5))\n",
    "    \n",
    "    #store5.step = step\n",
    "    #fig5.save( fullpath + \"strainrate\" + str(step).zfill(5))\n",
    "    \n",
    "    store6.step = step\n",
    "    fig6.save( fullpath + \"strainrate\" + str(step).zfill(5))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def swarm_update():\n",
    "    \n",
    "    #run swarm repopulation\n",
    "    repopulate()\n",
    "  \n",
    "    \n",
    "    #rebuild the material graph condition list, and apply to swarm\n",
    "    MG.build_condition_list(materialVariable)\n",
    "    materialVariable.data[:] = fn.branching.conditional(MG.condition_list).evaluate(swarm)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def markerLine_update():\n",
    "    cutoffDepth = 400e3/sf.lengthScale\n",
    "    mask = marker.swarm.particleCoordinates.data[:,1] < (mesh.maxCoord[1] - cutoffDepth)\n",
    "\n",
    "    with marker.swarm.deform_swarm():\n",
    "        marker.swarm.particleCoordinates.data[mask] = (999999.,999999.)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "_lambda = 0.5      #A dampening  applied to teh entire laplace vector\n",
    "laplaceLimit = 0.25 #fraction of inter-particle distance that is the maximum laplace displacement\n",
    "\n",
    "def heal_markers_update(smoothCycles, k):\n",
    "    \n",
    "    \"\"\"\n",
    "    Assumes: ds_fault\n",
    "    \"\"\"\n",
    "    \n",
    "    ###########\n",
    "    #Marker\n",
    "    ###########\n",
    "    \n",
    "    #Smoothing\n",
    "    for cyc in range(smoothCycles):\n",
    "        marker.rebuild()\n",
    "        if not marker.empty:\n",
    "            Dl = laplaceVector(marker, k = k, limit=laplaceLimit)\n",
    "        else:\n",
    "            Dl = 0.0  \n",
    "\n",
    "        with marker.swarm.deform_swarm():\n",
    "                marker.swarm.particleCoordinates.data[:] -= _lambda *Dl\n",
    "    \n",
    "    \n",
    "    #Addition\n",
    "    marker.rebuild()\n",
    "    if not marker.empty:\n",
    "        A = marker.neighbourMatrix( k =k)\n",
    "        newPoints = particlesToAdd(marker, A, _lowdist=2.*ds_fault) #start addding particles above _lowdist\n",
    "    else:\n",
    "        newPoints = np.empty((0,2))\n",
    "    marker.add_points(newPoints[:,0], newPoints[:,1])\n",
    "    \n",
    "    #Removal\n",
    "    #dummy arrays to use in case there's no marker on the proc \n",
    "    marker.rebuild()\n",
    "    midPoints = np.empty((0,2))\n",
    "    currentIds = np.empty((0,)).astype('bool') \n",
    "    if not marker.empty:\n",
    "        A = marker.neighbourMatrix( k =k)\n",
    "        midPoints, currentIds = neighbourDistanceQuery(marker, A, _lowdist=1e-6*ds_fault,_updist= 0.5*ds_fault)\n",
    "        #Need to delete those points first, before the \n",
    "    with marker.swarm.deform_swarm():\n",
    "        marker.swarm.particleCoordinates.data[currentIds] = (9999999., 9999999.)\n",
    "            \n",
    "    marker.add_points(midPoints[:,0], midPoints[:,1])\n",
    "    \n",
    "    \n",
    "    ###########\n",
    "    #Fault\n",
    "    ###########\n",
    "    \n",
    "    #Smoothing\n",
    "    for cyc in range(smoothCycles):\n",
    "        fault.rebuild()\n",
    "        if not fault.empty:\n",
    "            Dl = laplaceVector(fault, k = k, limit=laplaceLimit)\n",
    "        else:\n",
    "            Dl = 0.0  \n",
    "\n",
    "        with fault.swarm.deform_swarm():\n",
    "                fault.swarm.particleCoordinates.data[:] -= _lambda *Dl\n",
    "    \n",
    "    \n",
    "    #Addition\n",
    "    fault.rebuild()\n",
    "    if not fault.empty:\n",
    "        A = fault.neighbourMatrix( k =k)\n",
    "        newPoints = particlesToAdd(fault, A, _lowdist=2.*ds_fault)\n",
    "    else:\n",
    "        newPoints = np.empty((0,2))\n",
    "    fault.add_points(newPoints[:,0], newPoints[:,1])\n",
    "    \n",
    "    #Removal\n",
    "    fault.rebuild()\n",
    "    #dummy arrays to use in case there's no marker on the proc \n",
    "    midPoints = np.empty((0,2))\n",
    "    currentIds = np.empty((0,)).astype('bool')     \n",
    "    if not fault.empty:\n",
    "        A = fault.neighbourMatrix( k =k)\n",
    "        midPoints, currentIds = neighbourDistanceQuery(fault, A, _lowdist=1e-6*ds_fault,_updist= 0.5*ds_fault)\n",
    "        #Need to delete those points first, before the \n",
    "    with fault.swarm.deform_swarm():\n",
    "        fault.swarm.particleCoordinates.data[currentIds] = (9999999., 9999999.)\n",
    "            \n",
    "    fault.add_points(midPoints[:,0], midPoints[:,1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#heal_markers(1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def pressure_contour_points_update():\n",
    "    \n",
    "    criticalTempConds =  fn.branching.conditional([(operator.and_(proxyTempVariable > 0.9, proxyTempVariable < 0.98), True), \n",
    "                                      (True, False) ])\n",
    "\n",
    "    mask = criticalTempConds.evaluate(swarm)[:,0]\n",
    "    pointsRetain = swarm.particleCoordinates.data[mask,:]\n",
    "\n",
    "    pressureContourSwarm = uw.swarm.Swarm( mesh=mesh )\n",
    "    pressureContourSwarm.add_particles_with_coordinates(pointsRetain)\n",
    "    pressureOnContour = pressureContourSwarm.add_variable( dataType=\"double\", count=1 )\n",
    "    pressureOnContour.data[:] = pressureField.evaluate(pressureContourSwarm)\n",
    "    \n",
    "    fullpath = os.path.join(outputPath + \"files/\")\n",
    "    pressureContourSwarm.save( fullpath + \"pressureContourCoords\" + str(step).zfill(5))\n",
    "    pressureOnContour.save( fullpath + \"pressureContourVals\" + str(step).zfill(5))\n",
    "    \n",
    "    #these should / may go out of scope once the function returns anyway\n",
    "    del mask\n",
    "    del pointsRetain\n",
    "    del pressureOnContour\n",
    "    del pressureContourSwarm\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#create velocity magnitude fn\n",
    "velMagFn = uw.function.math.sqrt( uw.function.math.dot( velocityField, velocityField ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def files_update():\n",
    "    \n",
    "    #get all coords for the marker\n",
    "    marker.swarm.shadow_particles_fetch()\n",
    "    dims = marker.swarm.particleCoordinates.data.shape[1]\n",
    "    pc = np.append(marker.swarm.particleCoordinates.data,\n",
    "                       marker.swarm.particleCoordinates.data_shadow)\n",
    "    all_coords = pc.reshape(-1,dims)\n",
    "    pd = np.append(marker.director.data,\n",
    "                       marker.director.data_shadow)\n",
    "    all_directs = pd.reshape(-1,dims)\n",
    "    \n",
    "    #We don't evaluate on the fault but at a small distance in the normal direction\n",
    "    ds = ndp.faultThickness/2.\n",
    "    markerEvalPoints = all_coords - all_directs[...]*ds\n",
    "    ds2 = 1.5*ndp.faultThickness #distace into the mantle\n",
    "    mantleEvalPoints = all_coords - all_directs[...]*ds2\n",
    "    \n",
    "    \n",
    "    #Create the temp Swarm\n",
    "    markerEval = uw.swarm.Swarm( mesh=mesh )\n",
    "    markerEval.add_particles_with_coordinates(markerEvalPoints)\n",
    "    \n",
    "    mantleEval= uw.swarm.Swarm( mesh=mesh )\n",
    "    mantleEval.add_particles_with_coordinates(mantleEvalPoints)\n",
    "    \n",
    "    #Create the temp Swarm vars.\n",
    "    \n",
    "    markerVisc = uw.swarm.SwarmVariable(markerEval, 'double', 1)\n",
    "    markerSr2Inv = uw.swarm.SwarmVariable(markerEval, 'double', 1)\n",
    "    markerSrxx = uw.swarm.SwarmVariable(markerEval, 'double', 1)\n",
    "    markerSryy = uw.swarm.SwarmVariable(markerEval, 'double', 1)\n",
    "    markerEvalPoints = uw.swarm.SwarmVariable(markerEval, 'double', 2)\n",
    "    markerYieldStress = uw.swarm.SwarmVariable(markerEval, 'double', 1)\n",
    "    markerTemp = uw.swarm.SwarmVariable(markerEval, 'double', 1)\n",
    "    markerPressure = uw.swarm.SwarmVariable(markerEval, 'double', 1)\n",
    "    markerVelMag = uw.swarm.SwarmVariable(markerEval, 'double', 1)\n",
    "    markerAge = uw.swarm.SwarmVariable(markerEval, 'double', 1)\n",
    "    \n",
    "    mantleVelY = uw.swarm.SwarmVariable(mantleEval, 'double', 1)\n",
    "    mantleTemp = uw.swarm.SwarmVariable(mantleEval, 'double', 1)\n",
    "    mantleEvalPoints = uw.swarm.SwarmVariable(mantleEval, 'double', 2)\n",
    "\n",
    "    uplithEval = surfaceLine.swarm.particleCoordinates.data  - [0.0, 15e3/sf.lengthScale]\n",
    "    midlithEval = surfaceLine.swarm.particleCoordinates.data  - [0.0, 30e3/sf.lengthScale]\n",
    "    \n",
    "    \n",
    "    #define any NN interps we'll need\n",
    "\n",
    "    ix1, weights1, d1 = nn_evaluation(swarm.particleCoordinates.data, markerEval.particleCoordinates.data, n=5, weighted=True)\n",
    "    ix2, weights2, d2 = nn_evaluation(swarm.particleCoordinates.data, surfaceLine.swarm.particleCoordinates.data, n=5, weighted=True)\n",
    "\n",
    "\n",
    "    #safeguarding - prob not necessary, partial relic of earlier implementation \n",
    "    #Fault stuff  \n",
    "    if markerEval.particleCoordinates.data.shape[0]:\n",
    "        markerEvalPoints.data[:] = markerEval.particleCoordinates.data\n",
    "\n",
    "        #Update the data:\n",
    "        if len(weights1): #i.e. if there is anu markerLine in this proc\n",
    "            markerVisc.data[:,0] =  np.average(viscosityMapFn.evaluate(swarm)[:,0][ix1], weights=weights1, axis=len((weights1.shape)) - 1)\n",
    "        markerSr2Inv.data[:] = strainRate_2ndInvariant.evaluate(markerEval)\n",
    "        markerSrxx.data[:] = symStrainrate[0].evaluate(markerEval)\n",
    "        markerSryy.data[:] = symStrainrate[1].evaluate(markerEval)\n",
    "        markerYieldStress.data[:] = interfaceysf.evaluate(markerEval)\n",
    "        markerPressure.data[:] = pressureField.evaluate(markerEval) #only relavent for thermal models\n",
    "        if md.thermal:\n",
    "            markerTemp.data[:] = temperatureFn.evaluate(markerEval) #only relavent for thermal models\n",
    "        markerVelMag.data[:] = velMagFn.evaluate(markerEval)\n",
    "        markerAge.data[:] = lithAgeField.evaluate(markerEval)\n",
    "        \n",
    "    #Mantle stuff\n",
    "    if mantleEval.particleCoordinates.data.shape[0]:\n",
    "        mantleEvalPoints.data[:] = mantleEval.particleCoordinates.data\n",
    "        mantleVelY.data[:] = velocityField[1].evaluate(mantleEval)\n",
    "        mantleTemp.data[:] = temperatureField.evaluate(mantleEval)\n",
    "    \n",
    "    #Surface stuff \n",
    "    \n",
    "    surfVelx.data[:] = velocityField[0].evaluate(surfaceLine.swarm)\n",
    "    surfStrain.data[:] = symStrainrate[1].evaluate(surfaceLine.swarm)\n",
    "    surfPres.data[:] = pressureField.evaluate(surfaceLine.swarm)\n",
    "    \n",
    "    if md.thermal:\n",
    "        surfTgrad.data[:] = temperatureFn.fn_gradient[1].evaluate(surfaceLine.swarm)\n",
    "\n",
    "    if len(weights2):\n",
    "        surfVisc.data[:,0] =    np.average(viscosityMapFn.evaluate(swarm)[:,0][ix2], weights=weights2, axis=len((weights2.shape)) - 1)\n",
    "        if md.thermal:\n",
    "            surfTgrad.data[:] = temperatureFn.fn_gradient[1].evaluate(surfaceLine.swarm)\n",
    "\n",
    "    \n",
    "    #Mid lith stuff\n",
    "    \n",
    "    if midlithEval.shape[0]:\n",
    "        midlithEvalEvalPoints.data[:] = midlithEval\n",
    "        midlithVisc.data[:] = mantleRheologyFn.evaluate(midlithEval) #use mantleRheology to conserve resources\n",
    "        midlithSr2Inv.data[:] = strainRate_2ndInvariant.evaluate(midlithEval)\n",
    "        midlithStrainTens.data[:] = symStrainrate.evaluate(midlithEval)\n",
    "        midlithVelX.data[:] = velocityField[0].evaluate(midlithEval)\n",
    "        \n",
    "    if uplithEval.shape[0]:\n",
    "        uplithEvalEvalPoints.data[:] = uplithEval\n",
    "        uplithVisc.data[:] = mantleRheologyFn.evaluate(uplithEval) #use mantleRheology to conserve resources\n",
    "        uplithSr2Inv.data[:] = strainRate_2ndInvariant.evaluate(uplithEval)\n",
    "        uplithStrainTens.data[:] = symStrainrate.evaluate(uplithEval)\n",
    "        uplithVelX.data[:] = velocityField[0].evaluate(uplithEval)\n",
    "        \n",
    "    \n",
    "    \n",
    "    #Save the files:\n",
    "    fullpath = os.path.join(outputPath + \"files/\")\n",
    "    \n",
    "    #marker\n",
    "    markerEvalPoints.save( fullpath + \"markerEval\" + str(step).zfill(5))\n",
    "    markerYieldStress.save( fullpath + \"markerYieldStress\" + str(step).zfill(5))\n",
    "    markerTemp.save( fullpath + \"markerTemp\" + str(step).zfill(5))\n",
    "    markerVisc.save( fullpath + \"markerVisc\" + str(step).zfill(5))\n",
    "    markerSr2Inv.save( fullpath + \"markerSr2Inv\" + str(step).zfill(5))\n",
    "    markerSrxx.save( fullpath + \"markerSrxx\" + str(step).zfill(5))\n",
    "    markerSryy.save( fullpath + \"markerSryy\" + str(step).zfill(5))\n",
    "    markerPressure.save( fullpath + \"markerPressure\" + str(step).zfill(5))\n",
    "    markerVelMag.save( fullpath + \"markerVelMag\" + str(step).zfill(5))\n",
    "    markerAge.save( fullpath + \"markerAge\" + str(step).zfill(5))\n",
    "    \n",
    "    #mantle\n",
    "    mantleVelY.save( fullpath + \"mantleVelY\" + str(step).zfill(5))\n",
    "    mantleTemp.save( fullpath + \"mantleTemp\" + str(step).zfill(5))\n",
    "    mantleEvalPoints.save( fullpath + \"mantleEval\" + str(step).zfill(5))\n",
    "    \n",
    "    #suface\n",
    "    surfVelx.save( fullpath + \"surfVelx\" + str(step).zfill(5))\n",
    "    surfStrain.save( fullpath + \"surfStrain\" + str(step).zfill(5))\n",
    "    surfVisc.save( fullpath + \"surfVisc\" + str(step).zfill(5))\n",
    "    surfTgrad.save( fullpath + \"surfTgrad\" + str(step).zfill(5))\n",
    "    surfPres.save( fullpath + \"surfPres\" + str(step).zfill(5))\n",
    "    \n",
    "    #mid lith\n",
    "    midlithEvalEvalPoints.save( fullpath + \"midlithEvalEvalPoints\" + str(step).zfill(5))\n",
    "    midlithVisc.save( fullpath + \"midlithVisc\" + str(step).zfill(5))\n",
    "    midlithSr2Inv.save( fullpath + \"midlithSr2Inv\" + str(step).zfill(5))\n",
    "    midlithStrainTens.save( fullpath + \"midlithStrainTens\" + str(step).zfill(5))\n",
    "    midlithVelX.save(fullpath + \"midlithVelx\" + str(step).zfill(5))\n",
    "    \n",
    "    #up lith\n",
    "    uplithEvalEvalPoints.save( fullpath + \"uplithEvalEvalPoints\" + str(step).zfill(5))\n",
    "    uplithVisc.save( fullpath + \"uplithVisc\" + str(step).zfill(5))\n",
    "    uplithSr2Inv.save( fullpath + \"uplithSr2Inv\" + str(step).zfill(5))\n",
    "    uplithStrainTens.save( fullpath + \"uplithStrainTens\" + str(step).zfill(5))\n",
    "    uplithVelX.save(fullpath + \"uplithVelx\" + str(step).zfill(5))\n",
    "\n",
    "    \n",
    "    uw.barrier()\n",
    "    #big delete - all components of the temporary swarm \n",
    "    \n",
    "    del pc\n",
    "    del all_coords\n",
    "    del pd\n",
    "    del all_directs\n",
    "    del markerEvalPoints\n",
    "    del markerVisc\n",
    "    del markerSr2Inv\n",
    "    del markerSrxx \n",
    "    del markerSryy\n",
    "    del markerYieldStress\n",
    "    del markerEval\n",
    "    del mantleEval\n",
    "    del mantleVelY\n",
    "    del mantleEvalPoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#proximityVariable.evaluate(swarm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def swarm_to_mesh_update():\n",
    "    #define any NN interps we'll need\n",
    "    ix1, weights1, d1 = nn_evaluation(swarm.particleCoordinates.data, mesh.data, n=5, weighted=True)\n",
    "    \n",
    "    \n",
    "    #rebuild any mesh vars that are not self-updating\n",
    "    proximityField.data[:,0] =  np.average(proximityVariable.evaluate(swarm)[:,0][ix1], weights=weights1, axis=len((weights1.shape)) - 1)\n",
    "    viscosityField.data[:,0] =  np.average(viscosityMapFn.evaluate(swarm)[:,0][ix1], weights=weights1, axis=len((weights1.shape)) - 1)\n",
    "    strainRateField.data[:] = strainRate_2ndInvariant.evaluate(mesh)\n",
    "    \n",
    "    stressFieldX.data[:,0] = np.average(stressXVariableFn.evaluate(swarm)[ix1][:,:,0],weights=weights1, axis=1)\n",
    "    stressFieldMag.data[:,0] = np.average(stressMagVariableFn.evaluate(swarm)[ix1][:,:,0],weights=weights1, axis=1)\n",
    "    \n",
    "    lithAgeField.data[:,0] =  np.average(ageVariable.evaluate(swarm)[:,0][ix1], weights=weights1, axis=len((weights1.shape)) - 1)\n",
    "\n",
    "    \n",
    "    #ReBuild the principal stress vector\n",
    "    ssr = sym_strainRate.evaluate(mesh) #this does need to be here, \n",
    "        \n",
    "    principalAngles  = np.apply_along_axis(eig2d, 1, ssr[:, :])[:,2]\n",
    "    eig1.data[:,0] = np.cos(np.radians(principalAngles - 90.)) #most compressive \n",
    "    eig1.data[:,1] = np.sin(np.radians(principalAngles - 90.))\n",
    "    eig2.data[:,0] = np.cos(np.radians(principalAngles ))      #most extensive\n",
    "    eig2.data[:,1] = np.sin(np.radians(principalAngles ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def xdmfs_update():\n",
    "        \n",
    "    fullpath = os.path.join(outputPath + \"xdmf/\")\n",
    "    #if not os.path.exists(fullpath+\"mesh.h5\"):\n",
    "    #    _mH = mesh.save(fullpath+\"mesh.h5\")\n",
    "    \n",
    "    try:\n",
    "        _mH\n",
    "    except:\n",
    "        _mH = mesh.save(fullpath+\"mesh.h5\")\n",
    "    \n",
    "    \n",
    "    #Part 1\n",
    "    mh = _mH\n",
    "    vH = velocityField.save(fullpath + \"velocity_\" + str(step) +\".h5\")\n",
    "    if md.thermal:\n",
    "        tH = temperatureFn.save(fullpath + \"temp_\" + str(step) + \".h5\")\n",
    "    srH = strainRateField.save(fullpath + \"strainrate_\" + str(step) +\".h5\")\n",
    "    viscH = viscosityField.save(fullpath + \"visc_\" + str(step) + \".h5\")\n",
    "    \n",
    "    eH = eig1.save(fullpath + \"eig_\" + str(step) + \".h5\")\n",
    "    eH2 = eig2.save(fullpath + \"eig2_\" + str(step) + \".h5\")\n",
    "    sigXX = stressFieldX.save(fullpath + \"sigXX_\" + str(step) + \".h5\")\n",
    "    sigII = stressFieldMag.save(fullpath + \"sigII_\" + str(step) + \".h5\")\n",
    "    presH = pressureField.save(fullpath + \"pressure_\" + str(step) +\".h5\")\n",
    "   \n",
    "    #part2\n",
    "    \n",
    "    velocityField.xdmf(fullpath + \"velocity_\" + str(step), vH, 'velocity', mh, 'mesh', modeltime=time)\n",
    "    if md.thermal:\n",
    "        temperatureFn.xdmf(fullpath + \"temp_\" + str(step), tH, 'temperature', mh, 'mesh', modeltime=time)\n",
    "    strainRateField.xdmf(fullpath + \"strainrate_\" + str(step), srH, 'strainrate', mh, 'mesh', modeltime=time)\n",
    "    viscosityField.xdmf(fullpath + \"visc_\" + str(step), viscH, 'visc', mh, 'mesh', modeltime=time)\n",
    "    \n",
    "    eig1.xdmf(fullpath + \"eig_\" + str(step), eH, 'eig', mh, 'mesh', modeltime=time)\n",
    "    eig2.xdmf(fullpath + \"eig2_\" + str(step), eH2, 'eig2', mh, 'mesh', modeltime=time)\n",
    "    stressFieldX.xdmf(fullpath + \"sigXX_\" + str(step), sigXX, 'sigXX', mh, 'mesh', modeltime=time)\n",
    "    stressFieldMag.xdmf(fullpath + \"sigII_\" + str(step), sigII, 'sigII', mh, 'mesh', modeltime=time)\n",
    "    pressureField.xdmf(fullpath + \"pressure_\" + str(step), presH, 'pressure', mh, 'mesh', modeltime=time)\n",
    "\n",
    "    \n",
    "    \n",
    "    #temp \n",
    "    \n",
    "    #restrictionFnField.data[:] = szRfn150.evaluate(mesh)\n",
    "    #restrict = restrictionFnField.save(fullpath + \"restrict_\" + str(step) + \".h5\")\n",
    "    #restrictionFnField.xdmf(fullpath + \"restrict_\" + str(step), restrict, 'restrict', mh, 'mesh', modeltime=time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def update_wedge_pos():\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def valuesUpdateFn():\n",
    "    \n",
    "    \"\"\" \n",
    "    Assumes global variables:\n",
    "    * time\n",
    "    * step \n",
    "    ...\n",
    "    + many functions\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    #save the time and step\n",
    "    valuesDict.timeAtSave.append(time) \n",
    "    valuesDict.stepAtSave.append(step)\n",
    "    \n",
    "    #Save plate boundary locs.\n",
    "    #changes here (fn.value) should propagate through any connected funtions\n",
    "    _szVelGrads.reset()\n",
    "    dummyFn = _szVelGrads.evaluate(tWalls)\n",
    "    dummyVal = _szVelGrads.min_global_auxiliary()[0][0]\n",
    "    prevVal = subZoneLoc.value\n",
    "    subZoneLoc.value = (prevVal + dummyVal)/2. #a lazy smoothing of the update to help dampen fluctuations\n",
    "    \n",
    "    _spRidgeVelGrads.reset()\n",
    "    dummyFn = _spRidgeVelGrads.evaluate(tWalls)\n",
    "    dummyVal = _spRidgeVelGrads.max_global_auxiliary()[0][0]\n",
    "    spRidgeLoc.value = dummyVal\n",
    "    \n",
    "    _opRidgeVelGrads.reset()\n",
    "    dummyFn = _opRidgeVelGrads.evaluate(tWalls)\n",
    "    dummyVal = _opRidgeVelGrads.max_global_auxiliary()[0][0]\n",
    "    opRidgeLoc.value = dummyVal\n",
    "\n",
    "    valuesDict.opRidgeLoc.append(round(opRidgeLoc.value, 5))\n",
    "    valuesDict.subZoneLoc.append(round(subZoneLoc.value, 5))\n",
    "    valuesDict.spRidgeLoc.append(round(spRidgeLoc.value, 5))\n",
    "\n",
    "    \n",
    "    #Evaluate /save maxMins. These need resetting and evaluation\n",
    "    _mmVxSurf.reset()\n",
    "    dummyFn = _mmVxSurf.evaluate(mesh)\n",
    "        \n",
    "    _mmVxSurf.reset()\n",
    "    dummyFn = _mmVxSurf.evaluate(mesh)\n",
    "    \n",
    "    _wedgeHotCorner.reset()\n",
    "    dummyFn = _wedgeHotCorner.evaluate(mesh)\n",
    "    \n",
    "    \n",
    "    valuesDict.maxVxSurf.append(round(_mmVxSurf.max_global(), 5))\n",
    "    valuesDict.minVxSurf.append(round(_mmVxSurf.min_global(), 5))\n",
    "    \n",
    "    valuesDict.wedgeHotCornerX.append(round(_wedgeHotCorner.min_global_auxiliary()[0][0], 5))\n",
    "    valuesDict.wedgeHotCornerY.append(round(_wedgeHotCorner.min_global_auxiliary()[0][1], 5))\n",
    "\n",
    "\n",
    "\n",
    "    #Evaluate /save integrals \n",
    "    valuesDict.areaintLith.append(round(_areaintLith.evaluate()[0] , 5))\n",
    "    valuesDict.tempInt.append(round(_tempint.evaluate()[0] , 5))\n",
    "    valuesDict.vdintLith.append(round( _vdintLith.evaluate()[0], 5))    \n",
    "    valuesDict.potentialWork.append(round(_dwint.evaluate()[0], 5))\n",
    "    valuesDict.vdintLower.append(round(_vdintLower.evaluate()[0], 5))\n",
    "    valuesDict.areaintLower.append(round(_areaintLower.evaluate()[0], 5)) \n",
    "    valuesDict.vdintLowerBending.append(round(_vdintLowerBending.evaluate()[0], 5))\n",
    "    valuesDict.areaintLowerBending.append(round(_areaintLowerBending.evaluate()[0], 5)) \n",
    "    valuesDict.vdintUM.append(round(_vdintUM.evaluate()[0], 5))\n",
    "    valuesDict.vdintLM.append(round(_vdintLM.evaluate()[0], 5))\n",
    "    valuesDict.areaintSlabLM.append(round(_areaintSlabLM.evaluate()[0], 5))\n",
    "    valuesDict.vdintSlabLM.append(round(_vdintSlabLM.evaluate()[0], 5))\n",
    "    valuesDict.areaintInterface.append(round(_areaintInterface.evaluate()[0], 5))\n",
    "    valuesDict.vdintInterface.append(round(_vdintInterface.evaluate()[0], 5))\n",
    "    valuesDict.nusseltTop.append(round(_nuTop.evaluate()[0], 5))\n",
    "    valuesDict.critWedgeTempArea.append(round(_areaintcritWedgeTemp.evaluate()[0], 5))\n",
    "    \n",
    "\n",
    "    \n",
    "    #save\n",
    "    if uw.rank()==0:\n",
    "        fullpath = os.path.join(outputPath + \"model_data\")\n",
    "        #the '**' is important\n",
    "        np.savez(fullpath, **valuesDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Run any of the required update functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "swarm_to_mesh_update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "time = cp.time()  # Initial time\n",
    "step = cp.step()   # Initial timestep\n",
    "files_freq  = md.filesMy*(3600.*365.*24.)/sf.time  #applies to files and gldbs\n",
    "files_this_step = False\n",
    "next_image_step = (np.floor(time/files_freq)+ 1.) *files_freq \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#checkpoint at time zero\n",
    "if not cp.restart:\n",
    "    cp.saveObjs(step, time)\n",
    "    cp.saveDicts(step, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 1\n"
     ]
    }
   ],
   "source": [
    "while step < md.maxSteps:\n",
    "    \n",
    "    solver.solve(nonLinearIterate=True, nonLinearTolerance=md.nltol, callback_post_solve = pressure_calibrate)\n",
    "\n",
    "    \n",
    "    # main\n",
    "    time, step, dt, files_this_step, next_image_step = main_update(next_image_step)\n",
    "\n",
    "    # age\n",
    "    age_update()\n",
    "    \n",
    "   \n",
    "    #particles\n",
    "    #update static mesh variables\n",
    "    #markers / markerLines\n",
    "    if step % md.swarmUpdate == 0:\n",
    "        swarm_update()\n",
    "        swarm_to_mesh_update()\n",
    "        uw.barrier()\n",
    "        markerLine_update()\n",
    "        fault_update()\n",
    "    \n",
    "    #Heal the markers\n",
    "    if step % 5 == 0:\n",
    "        heal_markers_update(5, 4)\n",
    "    \n",
    "    #checkpoint\n",
    "    if step % md.checkpointEvery == 0:\n",
    "        cp.saveObjs(step, time)\n",
    "        cp.saveDicts(step, time)\n",
    "        \n",
    "        \n",
    "    #files\n",
    "    if files_this_step:\n",
    "        files_update()\n",
    "        pressure_contour_points_update()\n",
    "\n",
    " \n",
    "    #xdmfs\n",
    "    if files_this_step:\n",
    "        xdmfs_update()\n",
    "\n",
    "               \n",
    "    #output values\n",
    "    if files_this_step:\n",
    "        valuesUpdateFn()\n",
    "        \n",
    "            \n",
    "    #Viz\n",
    "    if files_this_step:\n",
    "        viz_update() \n",
    "  \n",
    "        \n",
    "    print 'step =',step\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "print 'step =',step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#ix1, weights1, d1 = nn_evaluation(swarm.particleCoordinates.data, mesh.data[tWalls.data], n=5, weighted=True)\n",
    "#surfStressData =    np.average(stressFn[1].evaluate(swarm)[:,0][ix1], weights=weights1, axis=len((weights1.shape)) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#vx = velocityField[0].evaluate(mesh.data[tWalls.data])\n",
    "#press = pressureField.evaluate(mesh.data[tWalls.data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#%pylab inline\n",
    "\n",
    "# new style method 1; unpack the axes\n",
    "#fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, sharey=False)\n",
    "#ax1.plot((-1.*surfStressData*sf.stress), c='r')\n",
    "#ax1.plot((press*sf.stress))\n",
    "#ax2.plot(vx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#We don't evaluate on the marker but, here\n",
    "#ds = ndp.faultThickness/2.\n",
    "#markerEval = marker.swarm.particleCoordinates.data - marker.director.data[...]*ds\n",
    "\n",
    "#marker2 = markerLine2D(mesh, velocityField,markerEval[:,0], markerEval[:,1], ndp.faultThickness,  6)\n",
    "\n",
    "#with marker2.swarm.deform_swarm():\n",
    "#    marker2.swarm.particleCoordinates.data[:] += marker2.director.data*ndp.faultThickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dims = marker.swarm.particleCoordinates.data.shape[1]\n",
    "pc = np.append(marker.swarm.particleCoordinates.data,\n",
    "                   marker.swarm.particleCoordinates.data_shadow)\n",
    "all_coords = pc.reshape(-1,dims)\n",
    "pd = np.append(marker.director.data,\n",
    "                   marker.director.data_shadow)\n",
    "all_directs = pd.reshape(-1,dims)\n",
    "\n",
    "#We don't evaluate on the fault but at a small distance in the normal direction\n",
    "ds = ndp.faultThickness/2.\n",
    "markerEvalPoints = all_coords - all_directs[...]*ds\n",
    "ds2 = 3.*ndp.faultThickness\n",
    "mantleEvalPoints = all_coords - all_directs[...]*ds2\n",
    "\n",
    "\n",
    "#Create the temp Swarm\n",
    "markerEval = uw.swarm.Swarm( mesh=mesh )\n",
    "markerEval.add_particles_with_coordinates(markerEvalPoints)\n",
    "\n",
    "mantleEval= uw.swarm.Swarm( mesh=mesh )\n",
    "mantleEval.add_particles_with_coordinates(mantleEvalPoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#fig1 = glucifer.Figure(figsize=(300*np.round(md.aspectRatio,2),300))\n",
    "\n",
    "#fig2.append( glucifer.objects.Points(swarm, materialVariable, pointSize=2, fn_mask=vizVariable))\n",
    "#fig1.append( glucifer.objects.Points(swarm, proximityVariable,pointSize=2))\n",
    "#fig1.append( glucifer.objects.Points(markerEval))\n",
    "#fig1.append( glucifer.objects.Points(swarm, proxyTempVariable))\n",
    "\n",
    "#fig1.append( glucifer.objects.Points(fault.swarm))\n",
    "\n",
    "#fig2.append( glucifer.objects.Points(testMarker.swarm))\n",
    "\n",
    "#fig1.show()\n",
    "#fig1.append( glucifer.objects.VectorArrows(mesh, velocityField, arrowHead=5, scaling=0.00005))\n",
    "#fig1.save_database('test.gldb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#import pickle\n",
    "##with open('dp.pkl', 'rb') as fp:\n",
    "#    dill = pickle.load(fp)\n",
    "#dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1250.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(160./96)*750."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "subZoneLocFn = fn.misc.constant(subZoneLoc)\n",
    "szRfn150 = 1. - cosine_taper(fn.math.abs(xFn - subZoneLocFn),pbbound, pbwidth)\n",
    "\n",
    "\n",
    "_testMM = fn.view.min_max(szRfn150*xFn**2, fn_auxiliary=xFn)\n",
    "dummyFn = _testMM.evaluate(tWalls)\n",
    "\n",
    "print(_testMM.max_global())\n",
    "\n",
    "_tempint = volumeint(szRfn150*xFn)\n",
    "print(_tempint.evaluate()[0])\n",
    "\n",
    "#reset underlying value\n",
    "subZoneLocFn.value = 0.7\n",
    "\n",
    "#shallow reevaluate\n",
    "_testMM.reset()\n",
    "\n",
    "dummyFn = _testMM.evaluate(tWalls)\n",
    "print(_testMM.max_global(), _testMM.max_global_auxiliary())\n",
    "\n",
    "print(_tempint.evaluate()[0])\n",
    "\n",
    "#full reevaluate\n",
    "_testMM = fn.view.min_max(szRfn150*xFn**2, fn_auxiliary=xFn)\n",
    "dummyFn = _testMM.evaluate(tWalls)\n",
    "print(_testMM.max_global(), _testMM.max_global_auxiliary())\n",
    "_tempint = volumeint(szRfn150*xFn)\n",
    "print(_tempint.evaluate()[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
